{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 패키지 import\n",
    "\n",
    "from konlpy.tag import Mecab, Kkma\n",
    "from collections import Counter\n",
    "import math\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 괄호 제거 (사이에 있는 내용도 제거) -------------------------------------------------------------------------------------\n",
    "# 괄호 위치 반환 함수------------------------------------\n",
    "\n",
    "\n",
    "def br_idx(s_br, e_br, txt):\n",
    "    braket_start = txt.find(s_br)\n",
    "    braket_end = txt.find(e_br)\n",
    "    result = [braket_start, braket_end]\n",
    "    return result\n",
    "\n",
    "\n",
    "# r = br_idx(\"(\", \")\", text)\n",
    "# print(r)\n",
    "# print(text[0])\n",
    "# --------------------------------------------------------\n",
    "# 괄호 종류별 인덱스 추출\n",
    "\n",
    "def rmTxt(text):\n",
    "    rm_txt = text\n",
    "\n",
    "    while True:\n",
    "        if \"(\" in rm_txt:\n",
    "            result = br_idx(\"(\", \")\", rm_txt)\n",
    "            rm_txt = rm_txt[:result[0]] + rm_txt[result[1]+1:]\n",
    "        elif \"[\" in rm_txt:\n",
    "            result = br_idx(\"[\", \"]\", rm_txt)\n",
    "            rm_txt = rm_txt[:result[0]] + rm_txt[result[1]+1:]\n",
    "        elif \"<\" in rm_txt:\n",
    "            result = br_idx(\"<\", \">\", rm_txt)\n",
    "            rm_txt = rm_txt[:result[0]] + rm_txt[result[1]+1:]\n",
    "        if (\"(\" not in rm_txt) and (\"[\" not in rm_txt) and (\"<\" not in rm_txt):\n",
    "            break\n",
    "    return rm_txt\n",
    "\n",
    "# print(rm_txt)\n",
    "# ------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 텍스트를 문장별로 쪼개기\n",
    "# kkma = Kkma()\n",
    "# sentences = kkma.sentences(text)\n",
    "\n",
    "def sen(rm_txt):\n",
    "    sentences = rm_txt.split(\".\")\n",
    "    sp_words = [\"'\", '\"', \",\", \"/\", \"\\\\\", \"=\", \"↓\", \"↑\", \"\\n\"]\n",
    "\n",
    "\n",
    "    for idx, sentence in enumerate(sentences):\n",
    "    #     print(idx)\n",
    "        sp_idx = 0\n",
    "        for sp_idx in range(len(sp_words)):\n",
    "            sentences[idx-1] = sentences[idx-1].strip(\" \")\n",
    "            if sp_words[sp_idx] in sentence:\n",
    "                sentences[idx] = sentences[idx].replace(sp_words[sp_idx], \"\")\n",
    "            if \"\" in sentences:\n",
    "                sentences.remove(\"\")\n",
    "                \n",
    "#                 print(\"있음\")\n",
    "    return sentences\n",
    "# print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Tokenizer\n",
    "# 텍스트 토큰화(텍스트 전처리단계)\n",
    "\n",
    "def token(text):\n",
    "    mecab = Mecab(dicpath=\"C:\\MeCab\\mecab-ko-dic\")\n",
    "    # mecab은 dictionary 위치를 넣어줘야함\n",
    "\n",
    "    # 명사 추출 테스트\n",
    "    nouns = mecab.nouns(text)\n",
    "    \n",
    "    return nouns\n",
    "# print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 중복 배제 추출\n",
    "\n",
    "# deduplicate_nouns = dedup_n\n",
    "\n",
    "def dedup(nouns):\n",
    "    dedup_n = []\n",
    "\n",
    "    for noun in nouns:\n",
    "    #     print(noun)\n",
    "        if noun not in dedup_n:\n",
    "            dedup_n.append(noun)\n",
    "    return dedup_n\n",
    "# 중복 배제된 단어 추출 완료\n",
    "# print(dedup_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf 함수\n",
    "# t : 단어, d : 문서 하나\n",
    "# 문서 전체의 단어들 d와 단어들의 t의 빈도수\n",
    "# f(t, d) 방식. f: frequency\n",
    "# tf(t,d) = log (f(t,d) + 1);\n",
    "\n",
    "def tf(t, d):\n",
    "    freq = np.zeros(len(t)).reshape(len(t), 1)\n",
    "#     print(len(d), len(t))\n",
    "    for n in range(len(t)):\n",
    "        count = 0\n",
    "        for m in range(len(d)):\n",
    "            if t[n] in d[m]:\n",
    "                count += 1\n",
    "                freq[n] = math.log(count)+1\n",
    "                \n",
    "    return freq\n",
    "\n",
    "# tf test\n",
    "# t = tf(dedup_n, nouns)\n",
    "# print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(t, D):\n",
    "    freq = np.zeros(len(t) * len(D)).reshape(len(t), len(D))\n",
    "    for idx_D in range(len(D)):\n",
    "        count = 0\n",
    "        for idx_t in range(len(t)):\n",
    "            if t[idx_t] in D[idx_D]:\n",
    "                count += 1\n",
    "            freq[idx_t][idx_D] = math.log(len(D)/(count+1))\n",
    "    return freq\n",
    "\n",
    "# idf test\n",
    "# i = idf(dedup_n, sentences)\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf 구현\n",
    "\n",
    "def tfidf(t, d, D):\n",
    "    tfidf = tf(t, d) * idf(t, D)\n",
    "    return tfidf\n",
    "\n",
    "# tf-idf test\n",
    "# ti = tfidf(dedup_n, nouns, sentences)\n",
    "# print(ti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치?\n",
    "\n",
    "# print(weight)\n",
    "\n",
    "def mk_graph(sentences):  \n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(sentences)\n",
    "    for x in range(len(sentences)):\n",
    "        for y in range(len(sentences)):\n",
    "            graph.add_edge(x, y, weight = weight[x, y])\n",
    "    return graph\n",
    "\n",
    "\n",
    "# print(reordered[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약할 텍스트의 타이틀을 입력해주세요\n",
      ">>> 미 '여름 시작' 메모리얼데이 연휴, 3천700만 명 이동 예상\n",
      "\n",
      "요약할 텍스트를 입력해주세요\n",
      ">>> 미국에서 코로나 19 규제가 완화되는 가운데 본격적인 여름 휴가철을 알리는 메모리얼 데이 연휴를 맞아 3천700만 명 이상이 장거리 여행에 나설 것으로 추산됐습니다.  USA투데이 등 미국 주요 언론은 현지시간 28일 전미자동차협회 발표를 인용해 이번 주말 시작되는 메모리얼 데이 연휴에 미국인 3천700만 명 이상이 집에서부터 최소 50마일, 80km 이상 떨어진 곳으로 여행할 예정이라고 전했습니다.  협회는 \"코로나19 팬데믹이 한창이던 작년 메모리얼 데이 연휴와 비교해 여행객이 60% 이상 증가했다\"며 팬데믹 이전인 2019년보다는 13% 적다고 설명했습니다.  여행객 대다수인 3천400만 명이 자동차를 이용한 도로 여행을 떠나고, 250만 명가량이 항공 여행을, 나머지 25만 명 정도가 버스와 기차 등 대중교통 수단을 이용할 계획입니다.  AP통신에 따르면 연휴 시작 전인 지난 27일, 미 전역의 공항에서 180만 명 이상이 항공편을 이용해 이동을 시작했습니다.\n",
      "\n",
      "텍스트가 정상적으로 입력되었습니다.\n",
      "\n",
      "본문의 문장은 총 5개 입니다.\n",
      "\n",
      "몇 문장으로 요약하시겠습니까?\n",
      ">>> 3\n",
      "\n",
      "정상적으로 입력되었습니다\n",
      "\n",
      "요약이 완료되었습니다.\n",
      "본문의 요약은 다음과 같습니다.\n",
      "\n",
      "\n",
      "제목 : 미 '여름 시작' 메모리얼데이 연휴, 3천700만 명 이동 예상\n",
      "--------------------------------------------------------------------------------\n",
      "내용 :\n",
      "미국에서 코로나 19 규제가 완화되는 가운데 본격적인 여름 휴가철을 알리는 메모리얼 데이 연휴를 맞아 3천700만 명 이상이 장거리 여행에 나설 것으로 추산됐습니다.USA투데이 등 미국 주요 언론은 현지시간 28일 전미자동차협회 발표를 인용해 이번 주말 시작되는 메모리얼 데이 연휴에 미국인 3천700만 명 이상이 집에서부터 최소 50마일 80km 이상 떨어진 곳으로 여행할 예정이라고 전했습니다.협회는 코로나19 팬데믹이 한창이던 작년 메모리얼 데이 연휴와 비교해 여행객이 60% 이상 증가했다며 팬데믹 이전인 2019년보다는 13% 적다고 설명했습니다\n",
      "--------------------------------------------------------------------------------\n",
      "계속하시려면 아무 글자나 입력해주세요. 엔터키를 누르면 종료합니다\n",
      ">>>\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    # 요약할 텍스트 입력\n",
    "    while True:\n",
    "        try:\n",
    "            title = input(\"요약할 텍스트의 타이틀을 입력해주세요\\n>>> \")\n",
    "            print()\n",
    "            text = input(\"요약할 텍스트를 입력해주세요\\n>>> \")\n",
    "            if text and title:\n",
    "                print()\n",
    "                print(\"텍스트가 정상적으로 입력되었습니다.\")\n",
    "                print()\n",
    "                break\n",
    "            else:\n",
    "                print()\n",
    "                print(\"텍스트가 정상적으로 입력되지 않았습니다. 다시 한 번 입력해주세요\")\n",
    "                print()\n",
    "        except:\n",
    "            print(\"오류가 발생하였습니다\")\n",
    "            \n",
    "    # ----------------------------------------------------------------------\n",
    "    rm_txt = rmTxt(text)\n",
    "    sentences = sen(rm_txt)\n",
    "    nouns = token(text)\n",
    "    dedup_n = dedup(nouns)\n",
    "    ti = tfidf(dedup_n, nouns, sentences)\n",
    "    weight = np.dot(ti.T, ti)\n",
    "    graph = mk_graph(sentences)\n",
    "    pagerank = nx.pagerank(graph, weight='weight')\n",
    "    reordered = sorted(pagerank, key=pagerank.get, reverse=True)     \n",
    "    # ----------------------------------------------------------------------\n",
    "    \n",
    "    try:\n",
    "        n_sen = int(input(f\"본문의 문장은 총 {len(sentences)}개 입니다.\\n\\n몇 문장으로 요약하시겠습니까?\\n>>> \"))\n",
    "        print()\n",
    "        if n_sen < len(sentences) and n_sen > 0:\n",
    "            print(\"정상적으로 입력되었습니다\")\n",
    "            print()\n",
    "        else:\n",
    "            print(f\"본문의 문장은 총 {len(sentences)}개 입니다.\")\n",
    "            print(f\"{len(sentences)} ~ 0 사이의 숫자를 입력해주세요\")\n",
    "            print()\n",
    "    except:\n",
    "        print(\"오류\")\n",
    "        \n",
    "    #------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    print(\"요약이 완료되었습니다.\")\n",
    "    print(\"본문의 요약은 다음과 같습니다.\")\n",
    "    print()\n",
    "    print()\n",
    "    print(f\"제목 : {title}\")\n",
    "    print(\"-\"*80)\n",
    "    print(\"내용 :\")\n",
    "    sent_temp = []\n",
    "    for i in range(n_sen):\n",
    "        sent_temp.append(reordered[i])\n",
    "\n",
    "    # print(sent_temp)\n",
    "    sent_asc = np.sort(np.array(sent_temp))\n",
    "    # print(sent_asc)\n",
    "\n",
    "    out_temp = []\n",
    "    for i in sent_asc:\n",
    "        out_temp.append(sentences[i])\n",
    "\n",
    "    out = \".\".join(out_temp)\n",
    "    print(out)\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    \n",
    "    finish = input(\"계속하시려면 아무 글자나 입력해주세요. 엔터키를 누르면 종료합니다\\n>>>\")\n",
    "    if not finish:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
