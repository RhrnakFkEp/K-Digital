{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP6.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-bOzfi1nX8aP",
        "MVEU8ybRX-tf",
        "pXQweGuVi8lD",
        "wdJFgndEpHMo",
        "VqAjveH_tyum",
        "ui7Uuaszu9Nd",
        "cpv-tSHbwilZ",
        "n--Tpak6xaYy",
        "8s5OhkZc2v9-",
        "Y5RgU7-8bB7H",
        "Lxrc45CEarfW",
        "iDxf-_P-a8yJ",
        "27EpnwNccogM",
        "iKZZgnP-cxr-",
        "45Mx9Ws9d2ls",
        "tHzzqsEefGnD",
        "J-6GQ4svfC7N",
        "V2wWFimgifW8",
        "czt4ntTnkLjx",
        "hde986yWsXU3",
        "-uPapW8itTPF",
        "WlaqeN7cuzFy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddzxRpPeXzGR"
      },
      "source": [
        "2021-06-17<br>\n",
        "NLP 강의 6일차"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFmcrz53X5R2"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bOzfi1nX8aP"
      },
      "source": [
        "# 글자 단위로 텍스트 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVEU8ybRX-tf"
      },
      "source": [
        "## 글자 단위 RNN 언어 모델"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCJEuYrjpaJe"
      },
      "source": [
        "![r](https://wikidocs.net/images/page/48649/char_rnn1.PNG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5YQmelWYBcA"
      },
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXb9DqH_YKs5",
        "outputId": "513b156b-6373-4b35-8180-ba1d3671c72e"
      },
      "source": [
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('11-0.txt', <http.client.HTTPMessage at 0x7fe4e9db08d0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkugWvvKYNpg"
      },
      "source": [
        "f = open('11-0.txt', 'rb')\n",
        "lines = []\n",
        "for line in f:\n",
        "  line = line.strip() \n",
        "  # strip을 통해 \\r, \\n을 제거\n",
        "  line = line.lower() # 소문자화 \n",
        "  line = line.decode('ascii', 'ignore') \n",
        "  # \\we2\\x80\\x99등과 같은 바이트 열 제거\n",
        "  if len(line)>0:\n",
        "    lines.append(line)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqmrCGL_YUgM",
        "outputId": "c1c37058-ab9a-4c4f-b061-4a6553a566b5"
      },
      "source": [
        "lines[:5] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
              " 'this ebook is for the use of anyone anywhere in the united states and',\n",
              " 'most other parts of the world at no cost and with almost no restrictions',\n",
              " 'whatsoever. you may copy it, give it away or re-use it under the terms',\n",
              " 'of the project gutenberg license included with this ebook or online at']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvwKI0zVY7bh",
        "outputId": "dd159025-6b14-44ed-e019-01a50ac1799e"
      },
      "source": [
        "text = \" \".join(lines)\n",
        "print(\"문자열의 길이 또는 총 글자의 개수 : %d\" %len(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문자열의 길이 또는 총 글자의 개수 : 159484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Doa9z_lKZDbc",
        "outputId": "fff9faeb-8856-4d48-dc3e-aa588e57a79e"
      },
      "source": [
        "print(text[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the projec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTuU1CClZEal",
        "outputId": "6d5820dd-1067-4879-9f63-e7454fe66787"
      },
      "source": [
        "# 글자 집합 생성\n",
        "\n",
        "char_vocab = sorted(list(set(text)))\n",
        "vocab_size = len(char_vocab)\n",
        "print(f\"글자 집합의 크기 : {vocab_size}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기 : 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia8K00w3ZVTB",
        "outputId": "bbfcd373-4854-4df1-f707-8a4ab4a97f69"
      },
      "source": [
        "print(char_vocab)\n",
        "# 알파벳, 숫자, 각종특수문자들이 포함되어있음"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Y434Uk0ZcLb",
        "outputId": "d9d8c54d-1610-4504-eccc-ffb43d99e130"
      },
      "source": [
        "# 글자 집합에 인덱스 부여하고 전부 출력\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
        "print(char_to_index)\n",
        "# 각각의 문자(글자)들에 인덱스가 부여됨"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ_TihhpZycM",
        "outputId": "3895c924-df62-45a3-ebf9-17475903f7ee"
      },
      "source": [
        "# 인덱스로부터 문자를 리턴\n",
        "\n",
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "  index_to_char[value] = key\n",
        "\n",
        "print(index_to_char)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: ' ', 1: '!', 2: '\"', 3: '#', 4: '$', 5: '%', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '?', 27: '[', 28: ']', 29: '_', 30: 'a', 31: 'b', 32: 'c', 33: 'd', 34: 'e', 35: 'f', 36: 'g', 37: 'h', 38: 'i', 39: 'j', 40: 'k', 41: 'l', 42: 'm', 43: 'n', 44: 'o', 45: 'p', 46: 'q', 47: 'r', 48: 's', 49: 't', 50: 'u', 51: 'v', 52: 'w', 53: 'x', 54: 'y', 55: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PSRaPwQIaN3F"
      },
      "source": [
        "# 훈련데이터 구성\n",
        "\n",
        "# e.g.\n",
        "# apple, sample 길이 4\n",
        "# 샘플길이가 4라면, 4개의 입력 글자 시퀀스로부터 4개의 출력 글자 시퀀스를 예측\n",
        "# 즉, RNN의 time step은 4번\n",
        "# appl -> pple\n",
        "# appl(입력시퀀스, train_x), pple(예측해야하는 시퀀스, train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIUn9EWEbAhP",
        "outputId": "730c95bb-0e60-4378-879d-00f37924db0f"
      },
      "source": [
        "# 15만 8천의 길이를 지닌 text 문자열로부터 다수의 문장 샘플들로 분리\n",
        "# 분리방법 : 문장 샘플의 길이를 정하고, 해당 길이만큼 문자열 전부를 등분\n",
        "\n",
        "seq_length = 60\n",
        "# 임의의 크기 지정\n",
        "n_samples = int(np.floor((len(text)-1) / seq_length))\n",
        "print(f\"문장 샘플의 수 : {n_samples}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문장 샘플의 수 : 2658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBUkIb6QbcSc"
      },
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(n_samples):\n",
        "  # 2658번 수행\n",
        "  x_sample = text[i * seq_length: (i+1) * seq_length]\n",
        "  # 문장 샘플을 1개씩 가져옴\n",
        "  x_encoded = [char_to_index[c] for c in x_sample]\n",
        "  # 하나의 문장 샘플에 대해서 정수 인코딩\n",
        "  train_x.append(x_encoded)\n",
        "\n",
        "  y_sample = text[i * seq_length + 1: (i + 1) * seq_length + 1]\n",
        "  # 오른쪽으로 한 칸 쉬프트 해서 y_sample에 넣음\n",
        "  y_encoded = [char_to_index[c] for c in y_sample]\n",
        "  train_y.append(y_encoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExLzzvqVcKK1",
        "outputId": "d64e1571-8512-4926-eecd-5eae8e03dfee"
      },
      "source": [
        "print(train_x[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[49, 37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5bXcMywcb0S",
        "outputId": "d7932df1-bbc4-4eb6-a7d1-c21423dd4fb2"
      },
      "source": [
        "print(train_y[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30, 43]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj4WpMGDcdWB",
        "outputId": "42ce9279-497c-4b44-b972-4e571a2e6dcb"
      },
      "source": [
        "print(train_x[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[43, 33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evZCYj3Vcha0",
        "outputId": "9b6368da-6311-4f3e-be69-9b72b20587ba"
      },
      "source": [
        "print(train_y[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54, 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVm57JjzcoiA"
      },
      "source": [
        "# x, y에 대한 원-핫 인코딩 수행(원-핫 벡터 생성)\n",
        "# 입력시퀀스에 대해 워드 임베딩하지 않음\n",
        "# embedding layer 사용 X\n",
        "\n",
        "train_x = to_categorical(train_x)\n",
        "train_y = to_categorical(train_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY6Mrz51iNcQ",
        "outputId": "76503b09-ad48-4667-c834-0f6bb9be2fd1"
      },
      "source": [
        "# 크기 출력\n",
        "\n",
        "print(f\"train_x의 크기 (shape) : {train_x.shape}\")\n",
        "print(f\"train_y의 크기 (shape) : {train_y.shape}\")\n",
        "\n",
        "# 샘플의 수 : 2658\n",
        "# 입력시퀀스 길이(input_length) : 60\n",
        "# 각 벡터의 차원(input_dim) : 56\n",
        "# 원-핫 벡터의 차원은 글자 집합의 크기인 56임."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x의 크기 (shape) : (2658, 60, 56)\n",
            "train_y의 크기 (shape) : (2658, 60, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWwjPVbsidbO"
      },
      "source": [
        "![](https://wikidocs.net/images/page/22886/rnn_image6between7.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXQweGuVi8lD"
      },
      "source": [
        "## 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RONpHTCZi-sN"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T715nXVFjL8n"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape = (None, train_x.shape[2]), return_sequences = True))\n",
        "model.add(LSTM(256, return_sequences = True))\n",
        "model.add(TimeDistributed(Dense(vocab_size, activation = \"softmax\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcLfBa9LjiBk",
        "outputId": "5dc92477-c796-4826-aa01-864368d5b5a1"
      },
      "source": [
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "model.fit(train_x, train_y, epochs = 80, verbose = 1)\n",
        "# verbose 1 : progress bar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "84/84 [==============================] - 10s 12ms/step - loss: 3.0692 - accuracy: 0.1822\n",
            "Epoch 2/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.7285 - accuracy: 0.2484\n",
            "Epoch 3/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.3862 - accuracy: 0.3305\n",
            "Epoch 4/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.2403 - accuracy: 0.3635\n",
            "Epoch 5/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.1308 - accuracy: 0.3914\n",
            "Epoch 6/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 2.0455 - accuracy: 0.4103\n",
            "Epoch 7/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.9796 - accuracy: 0.4275\n",
            "Epoch 8/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.9200 - accuracy: 0.4427\n",
            "Epoch 9/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.8710 - accuracy: 0.4572\n",
            "Epoch 10/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.8204 - accuracy: 0.4709\n",
            "Epoch 11/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.7785 - accuracy: 0.4831\n",
            "Epoch 12/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.7358 - accuracy: 0.4943\n",
            "Epoch 13/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.6982 - accuracy: 0.5045\n",
            "Epoch 14/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.6599 - accuracy: 0.5147\n",
            "Epoch 15/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.6238 - accuracy: 0.5239\n",
            "Epoch 16/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.5915 - accuracy: 0.5327\n",
            "Epoch 17/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.5609 - accuracy: 0.5405\n",
            "Epoch 18/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.5286 - accuracy: 0.5490\n",
            "Epoch 19/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.4963 - accuracy: 0.5579\n",
            "Epoch 20/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.4685 - accuracy: 0.5658\n",
            "Epoch 21/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.4377 - accuracy: 0.5734\n",
            "Epoch 22/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.4088 - accuracy: 0.5813\n",
            "Epoch 23/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.3805 - accuracy: 0.5897\n",
            "Epoch 24/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.3537 - accuracy: 0.5975\n",
            "Epoch 25/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.3284 - accuracy: 0.6041\n",
            "Epoch 26/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.3016 - accuracy: 0.6127\n",
            "Epoch 27/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.2713 - accuracy: 0.6217\n",
            "Epoch 28/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.2505 - accuracy: 0.6271\n",
            "Epoch 29/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.2150 - accuracy: 0.6375\n",
            "Epoch 30/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.1879 - accuracy: 0.6455\n",
            "Epoch 31/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.1617 - accuracy: 0.6523\n",
            "Epoch 32/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.1326 - accuracy: 0.6609\n",
            "Epoch 33/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.1139 - accuracy: 0.6663\n",
            "Epoch 34/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.0808 - accuracy: 0.6765\n",
            "Epoch 35/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.0497 - accuracy: 0.6849\n",
            "Epoch 36/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 1.0207 - accuracy: 0.6948\n",
            "Epoch 37/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.9958 - accuracy: 0.7017\n",
            "Epoch 38/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.9659 - accuracy: 0.7109\n",
            "Epoch 39/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.9414 - accuracy: 0.7183\n",
            "Epoch 40/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.9129 - accuracy: 0.7271\n",
            "Epoch 41/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.8879 - accuracy: 0.7347\n",
            "Epoch 42/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.8547 - accuracy: 0.7455\n",
            "Epoch 43/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.8324 - accuracy: 0.7528\n",
            "Epoch 44/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.8038 - accuracy: 0.7618\n",
            "Epoch 45/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.7724 - accuracy: 0.7716\n",
            "Epoch 46/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.7488 - accuracy: 0.7800\n",
            "Epoch 47/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.7272 - accuracy: 0.7863\n",
            "Epoch 48/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.7009 - accuracy: 0.7936\n",
            "Epoch 49/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.6740 - accuracy: 0.8030\n",
            "Epoch 50/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.6554 - accuracy: 0.8090\n",
            "Epoch 51/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.6248 - accuracy: 0.8196\n",
            "Epoch 52/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.5964 - accuracy: 0.8296\n",
            "Epoch 53/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.5762 - accuracy: 0.8351\n",
            "Epoch 54/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.5563 - accuracy: 0.8415\n",
            "Epoch 55/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.5478 - accuracy: 0.8432\n",
            "Epoch 56/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.5285 - accuracy: 0.8495\n",
            "Epoch 57/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4986 - accuracy: 0.8599\n",
            "Epoch 58/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4785 - accuracy: 0.8675\n",
            "Epoch 59/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4601 - accuracy: 0.8731\n",
            "Epoch 60/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4360 - accuracy: 0.8816\n",
            "Epoch 61/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4233 - accuracy: 0.8851\n",
            "Epoch 62/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.4177 - accuracy: 0.8858\n",
            "Epoch 63/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.3919 - accuracy: 0.8948\n",
            "Epoch 64/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.3714 - accuracy: 0.9022\n",
            "Epoch 65/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.3538 - accuracy: 0.9078\n",
            "Epoch 66/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.3351 - accuracy: 0.9154\n",
            "Epoch 67/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.3353 - accuracy: 0.9126\n",
            "Epoch 68/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.3156 - accuracy: 0.9198\n",
            "Epoch 69/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2949 - accuracy: 0.9271\n",
            "Epoch 70/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2936 - accuracy: 0.9261\n",
            "Epoch 71/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2961 - accuracy: 0.9238\n",
            "Epoch 72/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.2614 - accuracy: 0.9374\n",
            "Epoch 73/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.2580 - accuracy: 0.9370\n",
            "Epoch 74/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.2504 - accuracy: 0.9392\n",
            "Epoch 75/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2670 - accuracy: 0.9307\n",
            "Epoch 76/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2387 - accuracy: 0.9413\n",
            "Epoch 77/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2167 - accuracy: 0.9489\n",
            "Epoch 78/80\n",
            "84/84 [==============================] - 1s 10ms/step - loss: 0.2094 - accuracy: 0.9508\n",
            "Epoch 79/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.1966 - accuracy: 0.9542\n",
            "Epoch 80/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.1915 - accuracy: 0.9553\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe4e0288dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6vnAgrbjvRd"
      },
      "source": [
        "def sentence_generation(model, length):\n",
        "  ix = [np.random.randint(vocab_size)]\n",
        "  # 글자에 대한 랜덤 인덱스 생성\n",
        "  y_char = [index_to_char[ix[-1]]]\n",
        "  # 랜덤 인덱스로부터 글자 생성\n",
        "  print(ix[-1], \"번 글자\", y_char[-1], \"로 예측 시작\")\n",
        "  X = np.zeros((1, length, vocab_size))\n",
        "  # (1, length, 56) 크기의 X 생성. LSTM 입력 시퀀스 생성\n",
        "\n",
        "  for i in range(length):\n",
        "    X[0][i][ix[-1]] = 1\n",
        "    # X[0][i][예측한 글자 인덱스] = 1\n",
        "    # 예측 글자를 다음 입력 시퀀스에 추가\n",
        "    print(index_to_char[ix[-1]], end = \"\")\n",
        "    ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
        "    y_char.append(index_to_char[ix[-1]])\n",
        "  \n",
        "  return (\"\").join(y_char)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "k4GILQQcoKKt",
        "outputId": "b7aeeb53-fd69-404a-e4a7-50800fdbf0b8"
      },
      "source": [
        "sentence_generation(model, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "31 번 글자 b 로 예측 시작\n",
            "beginning, the king said gravely, and go on till you come to the game, the queen shrieked out. becom"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'beginning, the king said gravely, and go on till you come to the game, the queen shrieked out. become'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "kNvv5eVDoORT",
        "outputId": "7432a400-3d2d-4668-b45b-c318f8be8f59"
      },
      "source": [
        "sentence_generation(model, 30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "20 번 글자 6 로 예측 시작\n",
            "6 is the ress, or net relusion"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'6 is the ress, or net relusion '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdJFgndEpHMo"
      },
      "source": [
        "## 문자 단위 RNN(Char RNN)으로 텍스트 생성\n",
        "다 대 일(many to one)구조의 RNN을 글자 단위로 학습시키고, 텍스트 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqAjveH_tyum"
      },
      "source": [
        "### 데이터에 대한 이해와 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7sQ38Ykt2aJ"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Euvl6W03t8Bn"
      },
      "source": [
        "text = \"\"\"\n",
        "I get on with life as a programmer,\n",
        "I like to contemplate beer.\n",
        "But when I start to daydream,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "Do I love wine more than beer?\n",
        "\n",
        "I like to use words about beer.\n",
        "But when I stop my talking,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "I hate bugs and errors.\n",
        "But I just think back to wine,\n",
        "And I'm happy once again.\n",
        "\n",
        "I like to hang out with programming and deep learning.\n",
        "But when left alone,\n",
        "My mind turns straight to wine.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuiVXE-UuA2X",
        "outputId": "c6e3250d-9361-4655-86d6-c810e528d8c1"
      },
      "source": [
        "tokens = text.split()\n",
        "# \\n 제거\n",
        "text = \" \".join(tokens)\n",
        "print(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TcM4sPQ2uMhZ",
        "outputId": "52e6c27c-f2b0-4974-8ed7-561220beffdf"
      },
      "source": [
        "# 중복 제거 문자집합 생성\n",
        "\n",
        "char_vocab = sorted(list(set(text)))\n",
        "print(char_vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8ZPFtmpui3_",
        "outputId": "29ac8fe5-3111-44e3-c6fc-4fd75cbdea74"
      },
      "source": [
        "# 문자 집합 크기\n",
        "\n",
        "vocab_size = len(char_vocab)\n",
        "print(f\"글자 집합의 크기 : {vocab_size}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기 : 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3v2Tr_NUuqXf",
        "outputId": "55d8f109-b4af-4dea-f3c2-2314739d32bf"
      },
      "source": [
        "# 문자별 인덱스 할당\n",
        "\n",
        "char_to_index = dict((c, i) for i, c in enumerate(char_vocab))\n",
        "print(char_to_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui7Uuaszu9Nd"
      },
      "source": [
        "### example 5개의 입력 글자 시퀀스로부터 다음 글자 시퀀스 예측\n",
        "student\n",
        "- stude -> n\n",
        "- tuden -> t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF2xQ96nvQll",
        "outputId": "b05ef0c8-8b2a-4681-efd7-c324f879e79d"
      },
      "source": [
        "length  = 11\n",
        "sequences = []\n",
        "\n",
        "for i in range(length, len(text)):\n",
        "  seq = text[i - length : i]\n",
        "  # 길이 11의 문자열을 지속적으로 생성\n",
        "  sequences.append(seq)\n",
        "\n",
        "print(f\"총 훈련 샘플의 수 : {len(sequences)}\")\n",
        "print(sequences)\n",
        "# 생성한 시퀀스 확인\n",
        "\n",
        "# 한칸씩 쉬프트 한 결과가 출력됨"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 훈련 샘플의 수 : 426\n",
            "['I get on wi', ' get on wit', 'get on with', 'et on with ', 't on with l', ' on with li', 'on with lif', 'n with life', ' with life ', 'with life a', 'ith life as', 'th life as ', 'h life as a', ' life as a ', 'life as a p', 'ife as a pr', 'fe as a pro', 'e as a prog', ' as a progr', 'as a progra', 's a program', ' a programm', 'a programme', ' programmer', 'programmer,', 'rogrammer, ', 'ogrammer, I', 'grammer, I ', 'rammer, I l', 'ammer, I li', 'mmer, I lik', 'mer, I like', 'er, I like ', 'r, I like t', ', I like to', ' I like to ', 'I like to c', ' like to co', 'like to con', 'ike to cont', 'ke to conte', 'e to contem', ' to contemp', 'to contempl', 'o contempla', ' contemplat', 'contemplate', 'ontemplate ', 'ntemplate b', 'template be', 'emplate bee', 'mplate beer', 'plate beer.', 'late beer. ', 'ate beer. B', 'te beer. Bu', 'e beer. But', ' beer. But ', 'beer. But w', 'eer. But wh', 'er. But whe', 'r. But when', '. But when ', ' But when I', 'But when I ', 'ut when I s', 't when I st', ' when I sta', 'when I star', 'hen I start', 'en I start ', 'n I start t', ' I start to', 'I start to ', ' start to d', 'start to da', 'tart to day', 'art to dayd', 'rt to daydr', 't to daydre', ' to daydrea', 'to daydream', 'o daydream,', ' daydream, ', 'daydream, M', 'aydream, My', 'ydream, My ', 'dream, My m', 'ream, My mi', 'eam, My min', 'am, My mind', 'm, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine', 'ht to wine.', 't to wine. ', ' to wine. D', 'to wine. Do', 'o wine. Do ', ' wine. Do I', 'wine. Do I ', 'ine. Do I l', 'ne. Do I lo', 'e. Do I lov', '. Do I love', ' Do I love ', 'Do I love w', 'o I love wi', ' I love win', 'I love wine', ' love wine ', 'love wine m', 'ove wine mo', 've wine mor', 'e wine more', ' wine more ', 'wine more t', 'ine more th', 'ne more tha', 'e more than', ' more than ', 'more than b', 'ore than be', 're than bee', 'e than beer', ' than beer?', 'than beer? ', 'han beer? I', 'an beer? I ', 'n beer? I l', ' beer? I li', 'beer? I lik', 'eer? I like', 'er? I like ', 'r? I like t', '? I like to', ' I like to ', 'I like to u', ' like to us', 'like to use', 'ike to use ', 'ke to use w', 'e to use wo', ' to use wor', 'to use word', 'o use words', ' use words ', 'use words a', 'se words ab', 'e words abo', ' words abou', 'words about', 'ords about ', 'rds about b', 'ds about be', 's about bee', ' about beer', 'about beer.', 'bout beer. ', 'out beer. B', 'ut beer. Bu', 't beer. But', ' beer. But ', 'beer. But w', 'eer. But wh', 'er. But whe', 'r. But when', '. But when ', ' But when I', 'But when I ', 'ut when I s', 't when I st', ' when I sto', 'when I stop', 'hen I stop ', 'en I stop m', 'n I stop my', ' I stop my ', 'I stop my t', ' stop my ta', 'stop my tal', 'top my talk', 'op my talki', 'p my talkin', ' my talking', 'my talking,', 'y talking, ', ' talking, M', 'talking, My', 'alking, My ', 'lking, My m', 'king, My mi', 'ing, My min', 'ng, My mind', 'g, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine', 'ht to wine.', 't to wine. ', ' to wine. I', 'to wine. I ', 'o wine. I h', ' wine. I ha', 'wine. I hat', 'ine. I hate', 'ne. I hate ', 'e. I hate b', '. I hate bu', ' I hate bug', 'I hate bugs', ' hate bugs ', 'hate bugs a', 'ate bugs an', 'te bugs and', 'e bugs and ', ' bugs and e', 'bugs and er', 'ugs and err', 'gs and erro', 's and error', ' and errors', 'and errors.', 'nd errors. ', 'd errors. B', ' errors. Bu', 'errors. But', 'rrors. But ', 'rors. But I', 'ors. But I ', 'rs. But I j', 's. But I ju', '. But I jus', ' But I just', 'But I just ', 'ut I just t', 't I just th', ' I just thi', 'I just thin', ' just think', 'just think ', 'ust think b', 'st think ba', 't think bac', ' think back', 'think back ', 'hink back t', 'ink back to', 'nk back to ', 'k back to w', ' back to wi', 'back to win', 'ack to wine', 'ck to wine,', 'k to wine, ', ' to wine, A', 'to wine, An', 'o wine, And', ' wine, And ', 'wine, And I', \"ine, And I'\", \"ne, And I'm\", \"e, And I'm \", \", And I'm h\", \" And I'm ha\", \"And I'm hap\", \"nd I'm happ\", \"d I'm happy\", \" I'm happy \", \"I'm happy o\", \"'m happy on\", 'm happy onc', ' happy once', 'happy once ', 'appy once a', 'ppy once ag', 'py once aga', 'y once agai', ' once again', 'once again.', 'nce again. ', 'ce again. I', 'e again. I ', ' again. I l', 'again. I li', 'gain. I lik', 'ain. I like', 'in. I like ', 'n. I like t', '. I like to', ' I like to ', 'I like to h', ' like to ha', 'like to han', 'ike to hang', 'ke to hang ', 'e to hang o', ' to hang ou', 'to hang out', 'o hang out ', ' hang out w', 'hang out wi', 'ang out wit', 'ng out with', 'g out with ', ' out with p', 'out with pr', 'ut with pro', 't with prog', ' with progr', 'with progra', 'ith program', 'th programm', 'h programmi', ' programmin', 'programming', 'rogramming ', 'ogramming a', 'gramming an', 'ramming and', 'amming and ', 'mming and d', 'ming and de', 'ing and dee', 'ng and deep', 'g and deep ', ' and deep l', 'and deep le', 'nd deep lea', 'd deep lear', ' deep learn', 'deep learni', 'eep learnin', 'ep learning', 'p learning.', ' learning. ', 'learning. B', 'earning. Bu', 'arning. But', 'rning. But ', 'ning. But w', 'ing. But wh', 'ng. But whe', 'g. But when', '. But when ', ' But when l', 'But when le', 'ut when lef', 't when left', ' when left ', 'when left a', 'hen left al', 'en left alo', 'n left alon', ' left alone', 'left alone,', 'eft alone, ', 'ft alone, M', 't alone, My', ' alone, My ', 'alone, My m', 'lone, My mi', 'one, My min', 'ne, My mind', 'e, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOQB8qHbvldy"
      },
      "source": [
        "x = []\n",
        "\n",
        "for line in sequences:\n",
        "  # 전체 데이터에서 문장 샘플을 한 개씩 추출\n",
        "  temp_x = [char_to_index[char] for char in line]\n",
        "  # 문장 샘플에서 각 문자에 대해 정수 인코딩 수행\n",
        "  x.append(temp_x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEDuAJi7wGuw",
        "outputId": "e7397b3a-eaf4-4a98-ae77-f991c0922217"
      },
      "source": [
        "# 5 문장에 대하여 정수 인코딩된 결과 확인\n",
        " \n",
        "for line in x[:5]:\n",
        "  print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18]\n",
            "[0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28]\n",
            "[16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17]\n",
            "[14, 28, 0, 24, 23, 0, 31, 18, 28, 17, 0]\n",
            "[28, 0, 24, 23, 0, 31, 18, 28, 17, 0, 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52-boHCHwIx4"
      },
      "source": [
        "sequences = np.array(x)\n",
        "xx = sequences[:, :-1]\n",
        "y = sequences[:, -1]\n",
        "# 맨 마지막 위치의 글자 분리"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50Pcygw2we-t",
        "outputId": "2b806d20-b383-4cf1-f1e0-bf4480b49108"
      },
      "source": [
        "for line in x[:5]:\n",
        "  print(line)\n",
        "\n",
        "\n",
        "print()\n",
        "print(y[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 8  0 16 14 28  0 24 23  0 31 18]\n",
            "[ 0 16 14 28  0 24 23  0 31 18 28]\n",
            "[16 14 28  0 24 23  0 31 18 28 17]\n",
            "[14 28  0 24 23  0 31 18 28 17  0]\n",
            "[28  0 24 23  0 31 18 28 17  0 21]\n",
            "\n",
            "[18 28 17  0 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpv-tSHbwilZ"
      },
      "source": [
        "### 원-핫 인코딩 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZY2zGs5lww3Q"
      },
      "source": [
        "sequences = [to_categorical(x, num_classes = vocab_size) for x in xx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zk9qmfr2xHTX"
      },
      "source": [
        "x = np.array(sequences)\n",
        "\n",
        "y = to_categorical(y, num_classes = vocab_size)\n",
        "# y에 대한 원-핫 인코딩"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sKGS4mkxRZ8",
        "outputId": "a43d61e0-2388-410d-9a8a-805087e92b33"
      },
      "source": [
        "print(x.shape)\n",
        "\n",
        "# 샘플 수 : 426\n",
        "# 입력시퀀스 길이 : 10\n",
        "# 각 벡터의 차원 : 33"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(426, 10, 33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n--Tpak6xaYy"
      },
      "source": [
        "### 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B31d8cpuyzE0"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4iXCAYkzBog"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape = (x.shape[1], x.shape[2])))\n",
        "# (10, 33)\n",
        "model.add(Dense(vocab_size, activation = \"softmax\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ygy4Heczbua",
        "outputId": "c99665f5-ebb7-4515-b6b8-31a82e2fed09"
      },
      "source": [
        "model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
        "model.fit(x, y, epochs = 100, verbose = 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 1s 4ms/step - loss: 3.4450 - accuracy: 0.1643\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 3.1830 - accuracy: 0.1972\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 3.0001 - accuracy: 0.1972\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.9644 - accuracy: 0.1972\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.9464 - accuracy: 0.1972\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.9135 - accuracy: 0.1972\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.8880 - accuracy: 0.1972\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.8745 - accuracy: 0.1972\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.8186 - accuracy: 0.2042\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.7817 - accuracy: 0.1948\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.7205 - accuracy: 0.2183\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.6275 - accuracy: 0.2230\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 2.5621 - accuracy: 0.2371\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.4635 - accuracy: 0.2746\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.4156 - accuracy: 0.2887\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.3479 - accuracy: 0.3169\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.2299 - accuracy: 0.3286\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.1795 - accuracy: 0.3592\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.0859 - accuracy: 0.3662\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.0576 - accuracy: 0.3803\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.9705 - accuracy: 0.3967\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.9354 - accuracy: 0.4131\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.8897 - accuracy: 0.4601\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.8013 - accuracy: 0.4531\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 1.7742 - accuracy: 0.5000\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.6951 - accuracy: 0.5282\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.6495 - accuracy: 0.5188\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.5504 - accuracy: 0.5775\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.4985 - accuracy: 0.5939\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.4321 - accuracy: 0.6080\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 1.3609 - accuracy: 0.6385\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.3186 - accuracy: 0.6455\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.2503 - accuracy: 0.6432\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 1.1942 - accuracy: 0.7183\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.1508 - accuracy: 0.6972\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.0957 - accuracy: 0.7019\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.0304 - accuracy: 0.7488\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.9894 - accuracy: 0.7488\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.9452 - accuracy: 0.7700\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 3ms/step - loss: 0.8771 - accuracy: 0.8028\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.8004 - accuracy: 0.8310\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.7546 - accuracy: 0.8310\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.7128 - accuracy: 0.8662\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.7021 - accuracy: 0.8615\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.6473 - accuracy: 0.8803\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5869 - accuracy: 0.8967\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5735 - accuracy: 0.8967\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5244 - accuracy: 0.9178\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.9202\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.9484\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.9413\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4149 - accuracy: 0.9484\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3792 - accuracy: 0.9507\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3525 - accuracy: 0.9648\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.9624\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3370 - accuracy: 0.9648\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3146 - accuracy: 0.9671\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2902 - accuracy: 0.9812\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2886 - accuracy: 0.9601\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2631 - accuracy: 0.9695\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2576 - accuracy: 0.9671\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2342 - accuracy: 0.9695\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2187 - accuracy: 0.9742\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2017 - accuracy: 0.9789\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1959 - accuracy: 0.9812\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1883 - accuracy: 0.9789\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.9789\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1702 - accuracy: 0.9742\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1686 - accuracy: 0.9671\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1567 - accuracy: 0.9718\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.9718\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1440 - accuracy: 0.9789\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.9812\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1351 - accuracy: 0.9836\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1350 - accuracy: 0.9789\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1300 - accuracy: 0.9765\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1305 - accuracy: 0.9765\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9695\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1360 - accuracy: 0.9742\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1241 - accuracy: 0.9812\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1119 - accuracy: 0.9789\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1091 - accuracy: 0.9836\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1043 - accuracy: 0.9812\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1030 - accuracy: 0.9789\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0950 - accuracy: 0.9812\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9812\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0919 - accuracy: 0.9836\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.9789\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0917 - accuracy: 0.9836\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0918 - accuracy: 0.9765\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0921 - accuracy: 0.9812\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0896 - accuracy: 0.9789\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0822 - accuracy: 0.9836\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9765\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9812\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0821 - accuracy: 0.9765\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0761 - accuracy: 0.9859\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0758 - accuracy: 0.9836\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0716 - accuracy: 0.9836\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0703 - accuracy: 0.9836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe4942aab90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDrPALa6zm0n"
      },
      "source": [
        "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
        "  # 모델, 인덱스 정보, 문장 길이, 초기 시퀀스, 반복 횟수\n",
        "  \n",
        "  init_text = seed_text\n",
        "  # 문장 생성에 사용할 초기 시퀀스\n",
        "  sentence = \"\"\n",
        "\n",
        "  for _ in range(n):\n",
        "    encoded = [char_to_index[char] for char in seed_text]\n",
        "    # 현재 시퀀스에 대한 정수 인코딩\n",
        "    encoded = pad_sequences([encoded], maxlen = seq_length, padding = \"pre\")\n",
        "    # 데이터에 대한 패딩\n",
        "    encoded = to_categorical(encoded, num_classes = len(char_to_index))\n",
        "    result = model.predict_classes(encoded, verbose = 0)\n",
        "    # 입력한 x(현재 시퀀스)에 대하여 y를 예측하고, 예측한 글자(y)를 result에 할당\n",
        "\n",
        "    for char, index in char_to_index.items():\n",
        "      # 예측한 문자와 인덱스가 동일한 문자가 있을 때\n",
        "      if index == result:\n",
        "        # 해당 문자가 예측 문자이므로 break\n",
        "        break\n",
        "\n",
        "    seed_text = seed_text + char\n",
        "    # 현재 시퀀스 + 예측 문자를 현재 시퀀스에 변경\n",
        "    sentence = sentence + char\n",
        "    # 예측 문자를 문장에 저장\n",
        "\n",
        "  sentence = init_text + sentence\n",
        "  return sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uq8Zd64D1NFO",
        "outputId": "4bb1b81f-7369-4083-e71e-e7f9b648ab7a"
      },
      "source": [
        "print(sentence_generation(model, char_to_index, 10, \"I get on w\", 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "I get on with life as a programmer, I like to hang out with programming and deep learning. But when I start to\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OZmqa6u1Xid",
        "outputId": "aa95228f-e0b6-4a71-bddf-d673a624f881"
      },
      "source": [
        "print(sentence_generation(model, char_to_index, 10, \"Do I love wine\", 100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Do I love wine more than beer? I like to hang out with programming and deep learning. But when I start to daydream\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8s5OhkZc2v9-"
      },
      "source": [
        "# 네이버 쇼핑 리뷰 감성 분석\n",
        "- 총 200,000개 리뷰로 구성\n",
        "- 평점이 5점 만점에 1, 2, 4, 5인 리뷰들로 구성\n",
        "- 평점이 4, 5 인 리뷰들의 긍정 1, 부정 0\n",
        "- 감성 분류 수행"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5RgU7-8bB7H"
      },
      "source": [
        "## install, import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMsHxdesXQ_T",
        "outputId": "01a9cc20-08f6-4e55-b523-2bd4673837d8"
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8apY4YZX-Qg",
        "outputId": "47ab93fc-4d53-405c-99e8-c0ec25b1c18d"
      },
      "source": [
        "cd Mecab-ko-for-Google-Colab"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqMhf2vxXjiU",
        "outputId": "04484ef7-81ea-45d0-ad6b-afe9c20bf1d8"
      },
      "source": [
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-06-17 06:38:42--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::22c3:9b0a, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=q%2BPG6t2SD1vPYdVKvSlDMNHtNZM%3D&Expires=1623913224&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-17 06:38:42--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=q%2BPG6t2SD1vPYdVKvSlDMNHtNZM%3D&Expires=1623913224&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.133.163\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.133.163|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz.1’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  3.44MB/s    in 0.4s    \n",
            "\n",
            "2021-06-17 06:38:43 (3.44 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz.1’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-06-17 06:38:56--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::22c3:9b0a, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=9nH%2FCYZJ9jHoAOj%2FiHibj%2BCLlhg%3D&Expires=1623913471&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-17 06:38:56--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=9nH%2FCYZJ9jHoAOj%2FiHibj%2BCLlhg%3D&Expires=1623913471&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.106.220\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.106.220|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  32.0MB/s    in 1.5s    \n",
            "\n",
            "2021-06-17 06:38:58 (32.0 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz.1’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADLO9rWvY3Z7"
      },
      "source": [
        "from konlpy.tag import Mecab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SClS7iuKYBAx",
        "outputId": "af88d68a-18f2-4811-8a2a-a05361639bf5"
      },
      "source": [
        "mecab = Mecab()\n",
        "print(mecab.morphs(\"와~ 기대했던 신작인데 여기서는 취급하네요!ㅠㅠㅠ 다른곳은 취급 안해서 슬펐는데..ㅠㅠ 정발해주셔서 감사합니다\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['와', '~', '기대', '했', '던', '신작', '인데', '여기', '서', '는', '취급', '하', '네요', '!', 'ㅠㅠㅠ', '다른', '곳', '은', '취급', '안', '해서', '슬펐', '는데', '.', '.', 'ㅠㅠ', '정발', '해', '주', '셔서', '감사', '합니다']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9mIJOq9Y4Pf"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxrc45CEarfW"
      },
      "source": [
        "## 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DUH7OkoakRT",
        "outputId": "1e489fa9-59cd-4d4f-d118-8576d31a2a1a"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", filename=\"ratings_total.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_total.txt', <http.client.HTTPMessage at 0x7f3f16a47cd0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGwrJ-ApamjC"
      },
      "source": [
        "total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_FMos3Ua5PL",
        "outputId": "d08db842-08e0-4b36-9d21-f1853a2f9b09"
      },
      "source": [
        "print('전체 리뷰 갯수 :', len(total_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 리뷰 갯수 : 200000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Tqhd-4Oa6df",
        "outputId": "69201fc7-e00a-4822-f73c-9f1ffafbe4e0"
      },
      "source": [
        "total_data[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ratings</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ratings                                            reviews\n",
              "0        5                                            배공빠르고 굿\n",
              "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
              "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
              "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
              "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDxf-_P-a8yJ"
      },
      "source": [
        "## 훈련 데이터, 테스트 데이터 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQ3ddHaGa_ky",
        "outputId": "9ef17561-6314-48bb-c7f8-ad927ae986ec"
      },
      "source": [
        "total_data[\"label\"] = np.select([total_data.ratings > 3], [1], default = 0)\n",
        "total_data[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ratings</th>\n",
              "      <th>reviews</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ratings                                            reviews  label\n",
              "0        5                                            배공빠르고 굿      1\n",
              "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고      0\n",
              "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...      1\n",
              "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...      0\n",
              "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZ5yt7DxbN3k",
        "outputId": "748015d0-7d0e-48f8-fa41-6f5842859e89"
      },
      "source": [
        "# 중복을 제외한 각 열의 샘플 수 카운트\n",
        "\n",
        "total_data[\"ratings\"].nunique(), total_data[\"reviews\"].nunique(), total_data[\"label\"].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 199908, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eneq9dNfbh4v"
      },
      "source": [
        "# 중복되는 샘플 제거\n",
        "\n",
        "total_data.drop_duplicates(subset = [\"reviews\"], inplace = True)\n",
        "# reviews열 중 중복된 내용이 존재한다면 해당 샘플 제거"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SGJs9KCb9jo",
        "outputId": "c2b5e40f-bcbc-4030-f965-43d0242a22bf"
      },
      "source": [
        "# NULL 값 유무\n",
        "\n",
        "print(total_data.isnull().values.any())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGVxkAs_cCwn",
        "outputId": "14237577-70cf-49bb-94fa-7e4484123885"
      },
      "source": [
        "# 훈련데이터와 테스트 데이터를 3 : 1 비율로 분할\n",
        "\n",
        "train_data, test_data = train_test_split(total_data, test_size = 0.25, random_state=42)\n",
        "print('훈련용 리뷰의 갯수 : ', len(train_data))\n",
        "print('테스트용 리뷰의 갯수 : ', len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 리뷰의 갯수 :  149931\n",
            "테스트용 리뷰의 갯수 :  49977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27EpnwNccogM"
      },
      "source": [
        "## 레이블의 분포 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmmIt8UlclsO",
        "outputId": "e3af9771-185c-476e-fde6-1e3fac4ce90a"
      },
      "source": [
        "train_data['label'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3f19f7e1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dQz6I7NcrcI",
        "outputId": "efc3ee7e-a54c-4a4a-cb90-5f5b0e1391fd"
      },
      "source": [
        "print(train_data.groupby(\"label\").size().reset_index(name = \"count\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   label  count\n",
            "0      0  74918\n",
            "1      1  75013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKZZgnP-cxr-"
      },
      "source": [
        "## 데이터 정제\n",
        "정규 표현식을 이용하여 한글을 제외한 모든 문자 제거<br>\n",
        "빈 샘플이 생겼는지 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1p47Fmucy2P",
        "outputId": "41412133-6045-4ab6-e482-7c7445dddc7e"
      },
      "source": [
        "train_data['reviews'] = train_data['reviews'].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\"\")\n",
        "train_data['reviews'].replace('', np.nan, inplace=True)\n",
        "print(train_data.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ratings    0\n",
            "reviews    0\n",
            "label      0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOjUqWYvdcIu",
        "outputId": "b99f8d8c-c8b2-4b4c-fe8b-76e3ad842abb"
      },
      "source": [
        "test_data.drop_duplicates(subset=['reviews'], inplace=True)\n",
        "test_data['reviews'] = test_data['reviews'].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\"\")\n",
        "test_data['reviews'].replace('', np.nan, inplace=True)\n",
        "test_data = test_data.dropna(how='any')\n",
        "print('전처리 후 테스트용 샘플의 갯수 : ',len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전처리 후 테스트용 샘플의 갯수 :  49977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45Mx9Ws9d2ls"
      },
      "source": [
        "## 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8cyOkf9d3zS",
        "outputId": "c4e3262f-8dc3-47c7-f11c-bd3a75e7706e"
      },
      "source": [
        "mecab = Mecab()\n",
        "\n",
        "print(mecab.morphs(\"이런 상품도 상품이라고 허허허\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['이런', '상품', '도', '상품', '이', '라고', '허허허']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHzzqsEefGnD"
      },
      "source": [
        "## 불용어(stop words) 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciMw05y3d_Vq"
      },
      "source": [
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xgqlb_hUeWvj",
        "outputId": "dc9aea4f-1dba-4922-a616-86facea80b22"
      },
      "source": [
        "train_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)\n",
        "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZhYM3Gze_79"
      },
      "source": [
        "test_data['tokenized'] = test_data['reviews'].apply(mecab.morphs)\n",
        "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-6GQ4svfC7N"
      },
      "source": [
        "## 단어와 길이 분포 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yMwJsjFfJ4F"
      },
      "source": [
        "negative_words = np.hstack(train_data[train_data.label == 0][\"tokenized\"].values)\n",
        "positive_words = np.hstack(train_data[train_data.label == 1][\"tokenized\"].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WsPzKCETf-gM",
        "outputId": "f4068743-ebfb-469a-b4e4-d50615c52022"
      },
      "source": [
        "# Counter()를 사용하여 각 단어에 대한 빈도수 계산\n",
        "# 빈도 높은 상위 20개의 단어 \n",
        "\n",
        "# negative\n",
        "negative_word_count = Counter(negative_words)\n",
        "print(negative_word_count.most_common(20))\n",
        "\n",
        "# positive\n",
        "positive_word_count = Counter(positive_words)\n",
        "print(positive_word_count.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('네요', 31799), ('는데', 20295), ('안', 19718), ('어요', 14849), ('있', 13200), ('너무', 13058), ('했', 11783), ('좋', 9812), ('배송', 9677), ('같', 8997), ('구매', 8876), ('어', 8869), ('거', 8854), ('없', 8670), ('아요', 8642), ('습니다', 8436), ('그냥', 8355), ('되', 8345), ('잘', 8029), ('않', 7984)]\n",
            "[('좋', 39488), ('아요', 21184), ('네요', 19895), ('어요', 18686), ('잘', 18602), ('구매', 16171), ('습니다', 13320), ('있', 12391), ('배송', 12275), ('는데', 11670), ('했', 9818), ('합니다', 9801), ('먹', 9635), ('재', 9273), ('너무', 8397), ('같', 7868), ('만족', 7261), ('거', 6482), ('어', 6294), ('쓰', 6292)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tTsQxfLgjF6",
        "outputId": "a816d6b6-b4e4-4260-9e98-aa4cac059c0f"
      },
      "source": [
        "\n",
        "# Positive\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (10, 5))\n",
        "text_len = train_data[train_data[\"label\"] == 1][\"tokenized\"].map(lambda x: len(x))\n",
        "ax1.hist(text_len, color = \"red\")\n",
        "ax1.set_title(\"Positive Reviews\")\n",
        "ax1.set_xlabel(\"length of samples\")\n",
        "ax1.set_ylabel(\"number of samples\")\n",
        "print(f\"긍정 리뷰의 평균 길이 : {np.mean(text_len)}\")\n",
        "\n",
        "\n",
        "# Negative\n",
        "text_len = train_data[train_data[\"label\"] == 0][\"tokenized\"].map(lambda x: len(x))\n",
        "ax2.hist(text_len, color = \"blue\")\n",
        "ax2.set_title(\"Negative Reviews\")\n",
        "fig.suptitle(\"Words in texts\")\n",
        "ax2.set_xlabel(\"length of samples\")\n",
        "ax2.set_ylabel(\"number of samples\")\n",
        "print(f\"부정 리뷰의 평균 길이 : {np.mean(text_len)}\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "긍정 리뷰의 평균 길이 : 13.587751456414221\n",
            "부정 리뷰의 평균 길이 : 17.029512266744973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THe8AozJhiMd"
      },
      "source": [
        "x_train = train_data[\"tokenized\"].values\n",
        "y_train = train_data[\"label\"].values\n",
        "x_test = test_data[\"tokenized\"].values\n",
        "y_test = test_data[\"label\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2wWFimgifW8"
      },
      "source": [
        "## 정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVYYveacikgn"
      },
      "source": [
        "t = Tokenizer()\n",
        "\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQV32QsBioZG",
        "outputId": "247a2bf1-db5e-47a8-f855-dc86e211b494"
      },
      "source": [
        "threshold = 2\n",
        "\n",
        "total_cnt = len(t.word_index)\n",
        "# 단어의 수\n",
        "\n",
        "rare_cnt = 0\n",
        "total_freq = 0\n",
        "rare_freq = 0\n",
        "\n",
        "# 단어와 빈도수의 쌍을 key와 value로 받음\n",
        "for key, value in t.word_counts.items():\n",
        "  total_freq = total_freq + value\n",
        "\n",
        "  if (value < threshold):\n",
        "    rare_cnt += 1\n",
        "    rare_freq += value\n",
        "\n",
        "print(f\"단어 집합(vocabulary)의 크기 : {total_cnt}\")\n",
        "print(f\"등장 빈도가 %s 번 이하인 희귀단어의 수 : %s\" %(threshold - 1, rare_cnt))\n",
        "print(f\"단어 집합에서 희귀 단어의 비율 : {((rare_cnt)/total_cnt) * 100}\")\n",
        "print(f\"전체 등장 빈도에서 희귀다어 등장 빈도 비율 : {(rare_freq/total_freq) * 100}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 39998\n",
            "등장 빈도가 1 번 이하인 희귀단어의 수 : 18213\n",
            "단어 집합에서 희귀 단어의 비율 : 45.53477673883694\n",
            "전체 등장 빈도에서 희귀다어 등장 빈도 비율 : 0.7935688376196857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czt4ntTnkLjx"
      },
      "source": [
        "## 음흠"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efVWRrApozTY",
        "outputId": "2dc4830c-8990-4b87-f8d6-eebcd10c7aca"
      },
      "source": [
        "# 전체 단어 개수 중 빈도수가 2 이하인 단어 개수 제거\n",
        "# 0번 패딩 토큰과 1번 OOV 토큰을 고려해서 + 2\n",
        "\n",
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "print(f\"단어 집합의 크기 : {vocab_size}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 21787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1CCfKJNppXI",
        "outputId": "6267868c-0479-4b14-c623-9a14c9cbbf85"
      },
      "source": [
        "# 빈도수 2 이하인 단어 제거 전 기존 단어의 개수\n",
        "\n",
        "original_vocab_size = vocab_size + rare_cnt - 2 \n",
        "print(f\"원래 vocab size : {original_vocab_size}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원래 vocab size : 39998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXTnM2zvp8hA"
      },
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token = \"OOV\")\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SeiH4qUqN52",
        "outputId": "a3599bd6-d2fc-4f76-9194-fa02c9118a52"
      },
      "source": [
        "print(x_train[:3])\n",
        "print(x_test[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[67, 2060, 299, 14259, 263, 73, 6, 236, 168, 137, 805, 2951, 625, 2, 77, 62, 207, 40, 1343, 155, 3, 6], [482, 409, 52, 8530, 2561, 2517, 339, 2918, 250, 2357, 38, 473, 2], [46, 24, 825, 105, 35, 2372, 160, 7, 10, 8061, 4, 1319, 29, 140, 322, 41, 59, 160, 140, 7, 1916, 2, 113, 162, 1379, 323, 119, 136]]\n",
            "[[14, 704, 767, 116, 186, 252, 12], [339, 3904, 62, 3816, 1651], [11, 69, 2, 49, 164, 3, 27, 15, 6, 513, 289, 17, 92, 110, 564, 59, 7, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hde986yWsXU3"
      },
      "source": [
        "## 패딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "NEVukm1jsYi4",
        "outputId": "740a1a37-9eae-4b56-f2be-7eb8ac1548dd"
      },
      "source": [
        "print(f\"리뷰의 최대 길이 : {max(len(l) for l in x_train}\"))\n",
        "print(f\"리뷰의 평균 길이 : {sum(map(len, x_train))/len(x_train}\"))\n",
        "plt.hist([len(s) for s in x_train], bins = 50)\n",
        "plt.xlabel(\"length of smaples\")\n",
        "plt.ylabel(\"number of sample\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 85\n",
            "리뷰의 평균 길이 : 15.307541469075774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEGCAYAAACkQqisAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAd1klEQVR4nO3de5hcVZnv8e+PcFXBBJPJE5JgB42MkdEALeARPSiCAT0GZhwkXogYiY5wQGUcA3qEg8OZcFRUvEQDZAgOFxmBIQejoc1w0UeBdCAnF5CTAGHoTJO0BAgXjSS854+9CjZNV/fO7q6qrtTv8zz11N7vvq0qin6z1tp7LUUEZmZmZezS6AKYmVnzchIxM7PSnETMzKw0JxEzMyvNScTMzErbtdEFqLfRo0dHW1tbo4thZtZUli9f/oeIGNM73nJJpK2tjc7OzkYXw8ysqUh6pK+4m7PMzKw0JxEzMyvNScTMzEpzEjEzs9KcRMzMrDQnETMzK81JxMzMSnMSMTOz0pxEzMystJZ7Yn04a5vz8z7j6+d+oM4lMTMrxjURMzMrzUnEzMxKcxIxM7PSnETMzKw0JxEzMyvNScTMzEpzEjEzs9KcRMzMrLSaJRFJEyXdKuk+SWsknZXi+0rqkLQ2vY9KcUm6RNI6SSslHZI718y0/1pJM3PxQyWtSsdcIkm1+jxmZvZKtayJbAPOjogpwBHA6ZKmAHOApRExGVia1gGOAyan12xgHmRJBzgPOBw4DDivknjSPqfljptWw89jZma91CyJRER3RNyTlp8G7gfGA9OBhWm3hcAJaXk6cGVk7gRGShoHvB/oiIjNEfEE0AFMS9v2iYg7IyKAK3PnMjOzOqhLn4ikNuBg4C5gbER0p02PAWPT8njg0dxhXSnWX7yrj3hf158tqVNSZ09Pz6A+i5mZvaTmSUTSa4Drgc9HxJb8tlSDiFqXISLmR0R7RLSPGTOm1pczM2sZNU0iknYjSyBXRcQNKbwxNUWR3jel+AZgYu7wCSnWX3xCH3EzM6uTWt6dJeBy4P6IuDi3aRFQucNqJnBTLn5KukvrCOCp1Oy1BDhW0qjUoX4ssCRt2yLpiHStU3LnMjOzOqjlfCLvBD4BrJK0IsXOBeYC10maBTwCnJS2LQaOB9YBzwGnAkTEZklfB5al/S6IiM1p+XPAFcBewC/Sy8zM6qRmSSQifgNUe27j6D72D+D0KudaACzoI94JHDSIYpqZ2SD4iXUzMyvNScTMzEpzEjEzs9KcRMzMrDQnETMzK81JxMzMSnMSMTOz0pxEzMysNCcRMzMrzUnEzMxKcxIxM7PSnETMzKw0JxEzMyvNScTMzEpzEjEzs9JqObPhAkmbJK3OxX4qaUV6ra9MViWpTdIfc9t+lDvmUEmrJK2TdEmaxRBJ+0rqkLQ2vY+q1WcxM7O+1bImcgUwLR+IiI9ExNSImEo29/oNuc0PVrZFxGdz8XnAacDk9Kqccw6wNCImA0vTupmZ1VHNkkhE3AFs7mtbqk2cBFzT3zkkjQP2iYg708yHVwInpM3TgYVpeWEubmZmddKoPpF3ARsjYm0uNknSvZJul/SuFBsPdOX26UoxgLER0Z2WHwPGVruYpNmSOiV19vT0DNFHMDOzRiWRGby8FtIN7B8RBwNfBK6WtE/Rk6VaSvSzfX5EtEdE+5gxY8qW2czMetm13heUtCvw18ChlVhEbAW2puXlkh4E3gRsACbkDp+QYgAbJY2LiO7U7LWpHuU3M7OXNKIm8j7g9xHxYjOVpDGSRqTlA8g60B9KzVVbJB2R+lFOAW5Khy0CZqblmbm4mZnVSS1v8b0G+B1woKQuSbPSppN5ZYf6u4GV6ZbfnwGfjYhKp/zngMuAdcCDwC9SfC5wjKS1ZIlpbq0+i5mZ9a1mzVkRMaNK/JN9xK4nu+W3r/07gYP6iD8OHD24UpqZ2WD4iXUzMyvNScTMzEpzEjEzs9KcRMzMrDQnETMzK63uDxu2krY5P+8zvn7uB+pcEjOz2nBNxMzMSnMSMTOz0tyc1QSqNYuBm8bMrLFcEzEzs9KcRMzMrDQnETMzK61QEpF0pKRT0/IYSZNqWywzM2sGAyYRSecBXwbOSaHdgH+pZaHMzKw5FKmJnAh8CHgWICL+E9i7loUyM7PmUCSJ/Dk/h7mkV9e2SGZm1iyKJJHrJP0YGCnpNOBXwKUDHSRpgaRNklbnYudL2iBpRXodn9t2jqR1kh6Q9P5cfFqKrZM0JxefJOmuFP+ppN2LfmgzMxsaAyaRiPgm2ZS11wMHAl+LiO8VOPcVwLQ+4t+OiKnptRhA0hSyaXPfko75oaQRad71HwDHAVOAGWlfgIvSud4IPAHM6n0hMzOrrUJPrEdEB9CxIyeOiDsktRXcfTpwbURsBR6WtA44LG1bFxEPAUi6Fpgu6X7gvcBH0z4LgfOBeTtSRjMzG5yqNRFJT0va0sfraUlbBnHNMyStTM1do1JsPPBobp+uFKsWfx3wZERs6xWv9llmS+qU1NnT0zOIopuZWV7VJBIRe0fEPn289o6IfUpebx7wBmAq0A18q+R5dkhEzI+I9ohoHzNmTD0uaWbWEgo1Z0k6BDiS7A6t30TEvWUuFhEbc+e8FLg5rW4AJuZ2nZBiVIk/TtbRv2uqjeT3NzOzOinysOHXyPocXgeMBq6Q9NUyF5M0Lrd6IlC5c2sRcLKkPdLT8JOBu4FlwOR0J9buZJ3vi9Itx7cCH07HzwRuKlMmMzMrr0hN5GPA2yLiTwCS5gIrgH/s7yBJ1wBHAaMldQHnAUdJmkpWo1kPfAYgItZIug64D9gGnB4R29N5zgCWACOABRGxJl3iy8C1kv4RuBe4vOBnNjOzIVIkifwnsCfwp7S+BwWajiJiRh/hqn/oI+JC4MI+4ouBxX3EH+KlO7jMzKwBiiSRp4A1kjrIahDHAHdLugQgIs6sYfnMzGwYK5JEbkyvittqUxQzM2s2AyaRiFhYj4KYmVnzKXJ31gcl3Stp8xA9bGhmZjuJIs1Z3wH+GliVbq01MzMDio3i+yiw2gnEzMx6K1IT+QdgsaTbga2VYERcXLNSmZlZUyiSRC4EniF7VsRzdpiZ2YuKJJH9IuKgmpfEzMyaTpE+kcWSjq15SczMrOkUSSJ/B/xS0h99i6+ZmeUVedhw73oUxMzMmk/R+URGkQ3PvmclFhF31KpQZmbWHAZMIpI+DZxFNvHTCuAI4Hdkc5ybmVkLK9InchbwduCRiHgPcDDwZE1LZWZmTaFIEvlTbkKqPSLi98CBAx0kaYGkTZJW52LfkPR7SSsl3ShpZIq3pY77Fen1o9wxh0paJWmdpEskKcX3ldQhaW16H7WjH97MzAanSBLpSn/s/w3okHQT8EiB464ApvWKdQAHRcRbgf8HnJPb9mBETE2vz+bi84DTyPpkJufOOQdYGhGTgaVp3czM6mjAJBIRJ0bEkxFxPvA/yGYnPKHAcXcAm3vFbomIbWn1TrJ+lqrSnOz7RMSdaeyuK3PXnk429zvpfcAymZnZ0CoyFPwbJO1RWQXagFcNwbU/Bfwitz4pDTl/u6R3pdh4oCu3T1eKAYyNiO60/BgwttqFJM2W1Cmps6enZwiKbmZmUKw563pgu6Q3AvOBicDVg7mopK8A24CrUqgb2D8iDga+CFwtaZ+i50u1lKqjDEfE/Ihoj4j2MWPGDKLkZmaWVySJvJCaoE4EvhcRXwLGlb2gpE8CHwQ+VhlePiK2RsTjaXk58CDwJmADL2/ympBiABtTc1el2WtT2TKZmVk5RZLI85JmADOBm1NstzIXkzSNbGj5D0XEc7n4GEkj0vIBZB3oD6Xmqi2Sjkh3ZZ0C3JQOW5TKRHqvxM3MrE6KJJFTgXcAF0bEw5ImAT8Z6CBJ15A9lHigpC5Js4DvA3uT3eWVv5X33cBKSSuAnwGfjYhKp/zngMuAdWQ1lEo/ylzgGElrgfeldTMzq6MiY2fdB5yZW38YuKjAcTP6CF9eZd/ryfpe+trWCbxiKPrU/HX0QOUwM7PaKVITMTMz65OTiJmZlVY1iUj6SXo/q37FMTOzZtJfTeRQSfsBn5I0Ko1V9eKrXgU0M7Phq7+O9R+RjUl1ALCc7Gn1ikhxMzNrYVVrIhFxSUS8GVgQEQdExKTcywnEzMwK3eL7d5LeBlTGs7ojIlbWtlhmZtYMisxseCYwG7ghha6SND8ivlfTku3E2ub8vNFFMDMbEkXmWP80cHhEPAsg6SKyJ9GdRMzMWlyR50QEbM+tb+flnexmZtaiitRE/hm4S9KNaf0EqgxfYmZmraVIx/rFkm4DjkyhUyPi3pqWyszMmkKRmggRcQ9wT43LYmZmTcZjZ5mZWWmFaiLWfKrdRrx+7gfqXBIz25n1WxORNELSrWVPLmmBpE2SVudi+0rqkLQ2vY9KcUm6RNI6SSslHZI7Zmbaf62kmbn4oZJWpWMuSbMfmplZnfSbRCJiO/CCpNeWPP8VwLResTnA0oiYTDY215wUP45sWtzJZA83zoMs6QDnAYcDhwHnVRJP2ue03HG9r2VmZjVUpDnrGWCVpA7g2UowIs6sfsiL+9whqa1XeDpwVFpeCNwGfDnFr4yIAO6UNFLSuLRvR2W63FSOaemOsX0i4s4Uv5Ls9uNfYGZmdVEkidzAS0OeDIWxEdGdlh8Dxqbl8cCjuf26Uqy/eFcf8VeQNJusdsP+++8/yOKbmVlFkedEFkraC9g/Ih4YyotHREiKoTxnlevMB+YDtLe31/x6ZmatYsBbfCX9N2AF8Mu0PlXSokFcc2NqpiK9b0rxDcDE3H4TUqy/+IQ+4mZmVidFnhM5n6xD+0mAiFjB4CakWgRU7rCaCdyUi5+S7tI6AngqNXstAY5NsyuOAo4FlqRtWyQdke7KOiV3LjMzq4MifSLPR8RTve6efaHIySVdQ9YxPlpSF9ldVnOB6yTNAh4BTkq7LwaOB9YBzwGnAkTEZklfB5al/S6odLIDnyO7A2wvsg51d6qbmdVRkSSyRtJHgRGSJgNnAr8tcvKImFFl09F97BvA6VXOswBY0Ee8EzioSFnMzGzoFWnO+u/AW4CtwDXAFuDztSyUmZk1hyJ3Zz0HfCVNRhUR8XTti2VmZs2gyN1Zb5e0ClhJ9tDh/5V0aO2LZmZmw12RPpHLgc9FxK8BJB1JNlHVW2tZMDMzG/6K9IlsryQQgIj4DbCtdkUyM7NmUbUmkhtF93ZJPybrVA/gI2TjXZmZWYvrrznrW73Wz8ste+iQJuV5RsxsKFVNIhHxnnoWxMzMms+AHeuSRpINKdKW37/IUPBmZrZzK3J31mLgTmAVBYc7MTOz1lAkiewZEV+seUnMzKzpFLnF9yeSTpM0Ls2Pvm+astbMzFpckZrIn4FvAF/hpbuygsENB29mZjuBIknkbOCNEfGHWhfGzMyaS5HmrMr8HmZmZi9TpCbyLLBC0q1kw8EDvsXXzMyKJZF/S68hIelA4Ke50AHA14CRwGlAT4qfGxGL0zHnALOA7cCZEbEkxacB3wVGAJdFxNyhKqeZmQ2syHwiC4fyghHxADAVQNIIYANwI9l0uN+OiG/m95c0BTiZbGKs/YBfSXpT2vwD4BigC1gmaVFE3DeU5TUzs+qKPLH+MH2MlRURQ3F31tHAgxHxSK853POmA9dGxFbgYUnrgMPStnUR8VAq57VpXycRM7M6KdKc1Z5b3hP4W2ConhM5mWx04IozJJ0CdAJnR8QTwHiyJ+YrulIM4NFe8cP7uoik2cBsgP33339oSm5mZgPfnRURj+deGyLiO8Cgh3yVtDvwIeBfU2ge8Aaypq5uXjmKcGkRMT8i2iOifcyYMUN1WjOzllekOeuQ3OouZDWTIjWYgRwH3BMRGwEq7+malwI3p9UNwMTccRNSjH7iZmZWB0WSQb5GsA1YD5w0BNeeQa4pS9K4iOhOqycCq9PyIuBqSReTdaxPBu4GBEyWNIkseZwMfHQIymVmZgUVuTtryOcVkfRqsruqPpML/29JU8k68ddXtkXEGknXkXWYbwNOj4jt6TxnAEvIbvFdEBFrhrqsZmZWXZHmrD2Av+GV84lcUPaiEfEs8LpesU/0s/+FwIV9xBeTDVVvZmYNUKQ56ybgKWA5uSfWzczMiiSRCRExreYlsWHJc7KbWX+KDMD4W0l/VfOSmJlZ0ylSEzkS+GR6cn0r2V1RERFvrWnJzMxs2CuSRI6reSnMzKwpFbnF95F6FMTKqdZnYWZWD0X6RMzMzPrkJGJmZqU5iZiZWWlDMZCitSA/P2Jm4JqImZkNgpOImZmV5iRiZmaluU/EhpT7Ssxai2siZmZWWsOSiKT1klZJWiGpM8X2ldQhaW16H5XiknSJpHWSVuan7JU0M+2/VtLMRn0eM7NW1OiayHsiYmpEtKf1OcDSiJgMLE3rkI3fNTm9ZgPzIEs6wHnA4cBhwHmVxGNmZrXX6CTS23RgYVpeCJyQi18ZmTuBkZLGAe8HOiJic0Q8AXQAnvvEzKxOGplEArhF0nJJs1NsbER0p+XHgLFpeTzwaO7YrhSrFn8ZSbMldUrq7OnpGcrPYGbW0hp5d9aREbFB0l8AHZJ+n98YESEphuJCETEfmA/Q3t4+JOc0M7MG1kQiYkN63wTcSNansTE1U5HeN6XdNwATc4dPSLFqcTMzq4OG1EQkvRrYJSKeTsvHAhcAi4CZwNz0flM6ZBFwhqRryTrRn4qIbklLgP+V60w/Fjinjh/FBsnPlZg1t0Y1Z40FbpRUKcPVEfFLScuA6yTNAh4BTkr7LwaOB9YBzwGnAkTEZklfB5al/S6IiM31+xhmZq2tIUkkIh4C3tZH/HHg6D7iAZxe5VwLgAVDXUYzMxvYcLvF18zMmoiTiJmZleYkYmZmpXkUXxuWfNeWWXNwTcTMzEpzTWQIVPtXs5nZzs5JxAAnQjMrx81ZZmZWmpOImZmV5iRiZmaluU/Edhq+Ldis/lwTMTOz0pxEzMysNCcRMzMrzUnEzMxKq3vHuqSJwJVkE1MFMD8ivivpfOA0oCftem5ELE7HnAPMArYDZ0bEkhSfBnwXGAFcFhFz6/lZrDm4w92sdhpxd9Y24OyIuEfS3sBySR1p27cj4pv5nSVNAU4G3gLsB/xK0pvS5h8AxwBdwDJJiyLivrp8CjMzq38SiYhuoDstPy3pfmB8P4dMB66NiK3Aw5LWAYelbevSLImk+denA04iZmZ10tA+EUltwMHAXSl0hqSVkhZIGpVi44FHc4d1pVi1eF/XmS2pU1JnT09PX7uYmVkJDXvYUNJrgOuBz0fEFknzgK+T9ZN8HfgW8KmhuFZEzAfmA7S3t8dQnNN2jAd4NNs5NSSJSNqNLIFcFRE3AETExtz2S4Gb0+oGYGLu8AkpRj9xs9LcEW9WXN2bsyQJuBy4PyIuzsXH5XY7EVidlhcBJ0vaQ9IkYDJwN7AMmCxpkqTdyTrfF9XjM5iZWaYRNZF3Ap8AVklakWLnAjMkTSVrzloPfAYgItZIuo6sw3wbcHpEbAeQdAawhOwW3wURsaaeH8Rai2soZq/UiLuzfgOoj02L+znmQuDCPuKL+zvOzMxqy0+sm5lZaR4K3pqK7/IyG16cRMwGyX0l1srcnGVmZqU5iZiZWWluzjKrMzd/2c7EScRaljvpzQbPzVlmZlaaayJmw4SbuawZuSZiZmalOYmYmVlpbs4yq5Fad9y7+cuGAycRs51Mf8nLCcaGmpuzzMysNNdEzIY5P89iw5mTiJm5f8VKa/okImka8F2y2Q0vi4i5DS6S2bC1o7UaJxcbSFMnEUkjgB8AxwBdwDJJiyLivlpcz80KZhknF6to6iQCHAasi4iHACRdC0wnm4/dzOpsqP6h5WTUPJo9iYwHHs2tdwGH995J0mxgdlp9RtIDJa83GvhDyWNbgb+f6vzd9O9l348uamBJhqfh8Pt5fV/BZk8ihUTEfGD+YM8jqTMi2oegSDslfz/V+bvpn7+f/g3n76fZnxPZAEzMrU9IMTMzq4NmTyLLgMmSJknaHTgZWNTgMpmZtYymbs6KiG2SzgCWkN3iuyAi1tTwkoNuEtvJ+fupzt9N//z99G/Yfj+KiEaXwczMmlSzN2eZmVkDOYmYmVlpTiIFSZom6QFJ6yTNaXR5GknSREm3SrpP0hpJZ6X4vpI6JK1N76MaXdZGkTRC0r2Sbk7rkyTdlX4/P003grQkSSMl/UzS7yXdL+kd/u28RNIX0v9XqyVdI2nP4fz7cRIpIDe8ynHAFGCGpCmNLVVDbQPOjogpwBHA6en7mAMsjYjJwNK03qrOAu7PrV8EfDsi3gg8AcxqSKmGh+8Cv4yIvwTeRvY9+bcDSBoPnAm0R8RBZDcMncww/v04iRTz4vAqEfFnoDK8SkuKiO6IuCctP032R2A82XeyMO22EDihMSVsLEkTgA8Al6V1Ae8FfpZ2aeXv5rXAu4HLASLizxHxJP7t5O0K7CVpV+BVQDfD+PfjJFJMX8OrjG9QWYYVSW3AwcBdwNiI6E6bHgPGNqhYjfYd4B+AF9L664AnI2JbWm/l388koAf459Tcd5mkV+PfDgARsQH4JvAfZMnjKWA5w/j34yRipUl6DXA98PmI2JLfFtm94y13/7ikDwKbImJ5o8syTO0KHALMi4iDgWfp1XTVqr8dgNQXNJ0s2e4HvBqY1tBCDcBJpBgPr9KLpN3IEshVEXFDCm+UNC5tHwdsalT5GuidwIckrSdr9nwvWR/AyNQ8Aa39++kCuiLirrT+M7Kk4t9O5n3AwxHRExHPAzeQ/aaG7e/HSaQYD6+Sk9r4Lwfuj4iLc5sWATPT8kzgpnqXrdEi4pyImBARbWS/k3+PiI8BtwIfTru15HcDEBGPAY9KOjCFjiabuqHlfzvJfwBHSHpV+v+s8v0M29+Pn1gvSNLxZG3dleFVLmxwkRpG0pHAr4FVvNTufy5Zv8h1wP7AI8BJEbG5IYUcBiQdBfx9RHxQ0gFkNZN9gXuBj0fE1kaWr1EkTSW76WB34CHgVLJ/0Pq3A0j6n8BHyO6CvBf4NFkfyLD8/TiJmJlZaW7OMjOz0pxEzMysNCcRMzMrzUnEzMxKcxIxM7PSnERspybpmRqcc2q65buyfr6kvx/E+f42jWZ769CUsHQ51ksa3cgyWPNxEjHbcVOB4wfcq7hZwGkR8Z4hPKdZXTiJWMuQ9CVJyyStTA90Iakt1QIuTXM43CJpr7Tt7WnfFZK+keZ32B24APhIin8knX6KpNskPSTpzCrXnyFpVTrPRSn2NeBI4HJJ3+i1/zhJd6TrrJb0rhR/JpVnjaRfSTosd+0P5T7XryXdk17/JcWPSuf8ubL5cX4k6RV/ByR9XNLd6do/VjY/yghJV6SyrJL0hSH4z2LNLiL88munfQHPpPdjgfmAyP7xdDPZkORtZE8GT037XUf2NDDAauAdaXkusDotfxL4fu4a5wO/BfYARgOPA7v1Ksd+ZENajCEbhPDfgRPSttvI5o/oXfazga+k5RHA3mk5gOPS8o3ALcBuZHNzrEjxVwF7puXJQGdaPgr4E3BAOmcH8OG0bX0q/5uB/1P5DMAPgVOAQ4GOXPlGNvq/r1+Nf7kmYq3i2PS6F7gH+EuyP66QDXi3Ii0vB9okjST7o/27FL96gPP/PCK2RsQfyAYP7D2U+duB2yIbWG8bcBVZEuvPMuBUSecDfxXZ3C0AfwZ+mZZXAbdHNljfKrKkCFlSuVTSKuBfySZTq7g7srlxtgPXkNWE8o4mSxjLJK1I6weQDVFygKTvSZoGbMFa3q4D72K2UxDwTxHx45cFs/lQ8mMQbQf2KnH+3ucY9P9bEXGHpHeTTXB1haSLI+JK4PmIqIxX9ELl2hHxQm6k1y8AG8lqJ7uQ1T5ePHXvS/VaF7AwIs7pXSZJbwPeD3wWOAn4VNnPZzsH10SsVSwBPpXmQEHSeEl/UW3nyGbbe1rS4Sl0cm7z08DeO3j9u4H/Kml0mm55BnB7fwdIej2wMSIuJRuw8JAduN5rge6IeAH4BFnTVcVhaUTqXcgG+vtNr2OXAh+ufD/K5j9/fbpza5eIuB746g6Wx3ZSrolYS4iIWyS9GfhdNsI2zwAfJ6s1VDOLrEnoBbI/+E+l+K3AnNTU808Fr98taU46VmTNXwMN530U8CVJz6fynlLkWskPgeslnULW9PVsbtsy4PvAG1N5buxV1vskfRW4JSWa54HTgT+SzUhY+cfnK2oq1no8iq9ZFZJeExHPpOU5wLiIOKvBxRqU/PD0jS6L7RxcEzGr7gOSziH7/+QRsruyzCzHNREzMyvNHetmZlaak4iZmZXmJGJmZqU5iZiZWWlOImZmVtr/B7ebVieYhkHzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nsooNCesdqp"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if(len(s) <= max_len):\n",
        "      cnt += 1\n",
        "  print(f\"전체 샘플 중 길이가 {max_len}이하인 샘플의 비율 : {(cnt/len(nested_list)) * 100}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvXUNXq5tBSY",
        "outputId": "c1a7575b-f132-41e6-b301-af6223652810"
      },
      "source": [
        "max_len = 80\n",
        "below_threshold_len(max_len, x_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플 중 길이가 80이하인 샘플의 비율 : 99.99933302652553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFuh21v6tI8l"
      },
      "source": [
        "x_train = pad_sequences(x_train, maxlen = max_len)\n",
        "x_test = pad_sequences(x_test, maxlen = max_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGWFGHOHtQEs",
        "outputId": "2c98bf90-5df5-4c3e-a088-49709ffe278c"
      },
      "source": [
        "# 패딩 되었는지 확인\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(149931, 80)\n",
            "(49977, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uPapW8itTPF"
      },
      "source": [
        "## GRU 모델 생성 및 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dzwm0vx4tY6F"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, GRU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fyom68mtt2n"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(GRU(128))\n",
        "model.add(Dense(1, activation = \"sigmoid\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9okKGyGuDpl"
      },
      "source": [
        "# Early Stopping, Model Checkpoint\n",
        "# monitor : 어느것을 참고할건지?인듯?\n",
        "\n",
        "es = EarlyStopping(monitor = \"val_loss\", mode = \"min\", \n",
        "                   verbose = 1, patience = 4)\n",
        "mc = ModelCheckpoint(\"best_model.h5\", monitor = \"val_acc\", mode = \"max\", \n",
        "                     verbose = 1, save_best_only = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAdQg5y3ucV0",
        "outputId": "7a468fc3-dbbd-4772-a759-6b26005966e8"
      },
      "source": [
        "# compile\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"acc\"])\n",
        "history = model.fit(x_train, y_train, epochs = 30, callbacks = [es, mc], \n",
        "                    batch_size = 60, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2000/2000 [==============================] - 65s 28ms/step - loss: 0.2680 - acc: 0.8982 - val_loss: 0.2227 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.91863, saving model to best_model.h5\n",
            "Epoch 2/30\n",
            "2000/2000 [==============================] - 56s 28ms/step - loss: 0.1957 - acc: 0.9308 - val_loss: 0.2206 - val_acc: 0.9196\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.91863 to 0.91957, saving model to best_model.h5\n",
            "Epoch 3/30\n",
            "2000/2000 [==============================] - 54s 27ms/step - loss: 0.1630 - acc: 0.9430 - val_loss: 0.2265 - val_acc: 0.9167\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.91957\n",
            "Epoch 4/30\n",
            "2000/2000 [==============================] - 53s 27ms/step - loss: 0.1346 - acc: 0.9528 - val_loss: 0.2440 - val_acc: 0.9135\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.91957\n",
            "Epoch 5/30\n",
            "2000/2000 [==============================] - 53s 27ms/step - loss: 0.1115 - acc: 0.9608 - val_loss: 0.2811 - val_acc: 0.9121\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.91957\n",
            "Epoch 6/30\n",
            "2000/2000 [==============================] - 53s 27ms/step - loss: 0.0929 - acc: 0.9675 - val_loss: 0.2987 - val_acc: 0.9081\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.91957\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHG6HLK1yPZo",
        "outputId": "86f5921b-04d9-4954-bb54-a12983728b09"
      },
      "source": [
        "# 모델 저장\n",
        "\n",
        "loaded_model = load_model(\"best_model.h5\")\n",
        "print(\"\\n테스트 정확도 : %.4f\"%(loaded_model.evaluate(x_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 6s 4ms/step - loss: 0.2242 - acc: 0.9178\n",
            "\n",
            "테스트 정확도 : 0.9178\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlaqeN7cuzFy"
      },
      "source": [
        "## 리뷰 예측"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIyFplybxM07"
      },
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  \n",
        "  # 토큰화\n",
        "  new_sentence = mecab.morphs(new_sentence)\n",
        "  # 불용어 제거\n",
        "  new_sentence = [word for word in new_sentence if not word in stopwords]\n",
        "  encoded = tokenizer.texts_to_sequences([new_sentence])\n",
        "  # 패딩\n",
        "  pad_new = pad_sequences(encoded, maxlen=max_len)\n",
        "\n",
        "  # 예측\n",
        "  score = float(loaded_model.predict(pad_new)) \n",
        "  \n",
        "  if (score >0.5):\n",
        "    print(\"{:.2f}% 확률로 긍정 리뷰입니다\".format(score*100))\n",
        "  else:\n",
        "    print(\"{:.2f}% 확률로 부정 리뷰입니다\".format((1-score)*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgMfDGafyI7f",
        "outputId": "b59e3e24-bc46-4cd3-8e81-4a1a495017b3"
      },
      "source": [
        "sentiment_predict(\"이 상품 진짜 좋아요. 강추입니다\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96.36% 확률로 긍정 리뷰입니다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjv_a-USyju8",
        "outputId": "d14d3aa6-71d0-40a6-8030-87d6b491bf72"
      },
      "source": [
        "sentiment_predict(\"와......\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "95.47% 확률로 부정 리뷰입니다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxiK9vZBzOt0",
        "outputId": "76aaba0d-21fa-4c80-834b-bc8d415a3e02"
      },
      "source": [
        "sentiment_predict(\"와\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "62.91% 확률로 부정 리뷰입니다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDAQcntNzQ9p",
        "outputId": "f5902a9f-fbb3-4407-eb73-12d5cf8bbd0c"
      },
      "source": [
        "sentiment_predict(\"ㅋ\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57.07% 확률로 긍정 리뷰입니다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mbftvkaYzUM7",
        "outputId": "eb481522-bb2d-43ba-b074-c395bb98a34c"
      },
      "source": [
        "sentiment_predict(\"...\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54.89% 확률로 부정 리뷰입니다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cMxgWZGzXj9",
        "outputId": "537e09ef-40f9-46be-d210-f0139f7eb91a"
      },
      "source": [
        "sentiment_predict(\"별이 다섯개\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.69% 확률로 부정 리뷰입니다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vmQ15EMzYxr"
      },
      "source": [
        "# 문자 단위(Character-level)로 구현한 seq2seq 번역기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hcah9eSGzdEE",
        "outputId": "fa94d6dd-296d-4194-e5f5-1ce4fd72d667"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcOl3WjG5BUM",
        "outputId": "8ee8c9bf-2520-41ba-e780-c0c8cb2a9011"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmW8Xz1d6Ubf"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "0om1rV435Dkz",
        "outputId": "6af5c5b1-3658-45e5-f571-b7e737f6e53b"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/dataset/fra.txt\"\n",
        "lines = pd.read_csv(file_path, names = [\"eng\", \"fra\", \"cc\"], sep = \"\\t\")\n",
        "lines.sample(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "      <th>cc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5826</th>\n",
              "      <td>Tom got weak.</td>\n",
              "      <td>Tom devint faible.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146824</th>\n",
              "      <td>You're not from around here, are you?</td>\n",
              "      <td>Vous n'êtes pas d'ici, n'est-ce pas ?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54053</th>\n",
              "      <td>I attended the seminar.</td>\n",
              "      <td>J'ai assisté au séminaire.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58526</th>\n",
              "      <td>What should I be doing?</td>\n",
              "      <td>Que devrais-je faire ?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116024</th>\n",
              "      <td>Where were you that whole time?</td>\n",
              "      <td>Où étiez-vous, tout ce temps ?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          eng  ...                                                 cc\n",
              "5826                            Tom got weak.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #6...\n",
              "146824  You're not from around here, are you?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "54053                 I attended the seminar.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "58526                 What should I be doing?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "116024        Where were you that whole time?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "45n6GIDV5a00",
        "outputId": "c546d22e-51a4-41db-f7d1-1ed92145b8e8"
      },
      "source": [
        "# 일부만 추출\n",
        "\n",
        "lines = lines[[\"eng\", \"fra\"]][:50000]\n",
        "lines.sample(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29223</th>\n",
              "      <td>I was born in 1972.</td>\n",
              "      <td>Je suis né en 1972.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5537</th>\n",
              "      <td>She went out.</td>\n",
              "      <td>Elle sortit.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28809</th>\n",
              "      <td>I know that's true.</td>\n",
              "      <td>Je sais que c'est vrai.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43429</th>\n",
              "      <td>The lakes are frozen.</td>\n",
              "      <td>Les lacs sont gelés.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49743</th>\n",
              "      <td>Please take my advice.</td>\n",
              "      <td>S'il vous plaît, suivez mon conseil.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          eng                                   fra\n",
              "29223     I was born in 1972.                   Je suis né en 1972.\n",
              "5537            She went out.                          Elle sortit.\n",
              "28809     I know that's true.               Je sais que c'est vrai.\n",
              "43429   The lakes are frozen.                  Les lacs sont gelés.\n",
              "49743  Please take my advice.  S'il vous plaît, suivez mon conseil."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "BLyZKvms5-Hd",
        "outputId": "1dbf8970-5a84-4b42-a867-19736d874c93"
      },
      "source": [
        "# fra에 시작 토큰과 종료 토큰 추가\n",
        "\n",
        "sos_token = \"\\t\"\n",
        "eos_token = \"\\n\"\n",
        "lines.fra = lines.fra.apply(lambda x: \"\\t\" + x + \"\\n\")\n",
        "print(f\"전체 샘플의 수 : {len(lines)}\")\n",
        "lines.sample(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수 : 50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>26711</th>\n",
              "      <td>You came too late.</td>\n",
              "      <td>\\tVous êtes venues trop tard.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21692</th>\n",
              "      <td>Your face is red.</td>\n",
              "      <td>\\tTon visage est rouge.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4512</th>\n",
              "      <td>Go for broke!</td>\n",
              "      <td>\\tJouez le tout pour le tout !\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4215</th>\n",
              "      <td>You're safe.</td>\n",
              "      <td>\\tVous êtes sauf.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4358</th>\n",
              "      <td>Can we leave?</td>\n",
              "      <td>\\tPouvons-nous partir ?\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      eng                               fra\n",
              "26711  You came too late.   \\tVous êtes venues trop tard.\\n\n",
              "21692   Your face is red.         \\tTon visage est rouge.\\n\n",
              "4512        Go for broke!  \\tJouez le tout pour le tout !\\n\n",
              "4215         You're safe.               \\tVous êtes sauf.\\n\n",
              "4358        Can we leave?         \\tPouvons-nous partir ?\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulfkkv1x6nJL"
      },
      "source": [
        "## 단어장 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbNLa4Y_6-EQ",
        "outputId": "c4016ead-e9b6-4d33-911b-508502ac6abe"
      },
      "source": [
        "# 영어(eng) char 단위로 토큰화\n",
        "\n",
        "eng_tokenizer = Tokenizer(char_level = True)\n",
        "# 문자 단위 토큰화\n",
        "eng_tokenizer.fit_on_texts(lines.eng)\n",
        "# 50000개의 행을 지닌 eng의 각 행에 토큰화 수행\n",
        "\n",
        "input_text = eng_tokenizer.texts_to_sequences(lines.eng)\n",
        "input_text[:3]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[19, 3, 8], [19, 3, 8], [19, 3, 8]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Pz4vG-H7Uog",
        "outputId": "c946d77a-0c91-480f-9ef9-214a2514626b"
      },
      "source": [
        "# 프랑스어(fra) char 단위로 토큰화\n",
        "\n",
        "fra_tokenizer = Tokenizer(char_level = True)\n",
        "fra_tokenizer.fit_on_texts(lines.fra)\n",
        "\n",
        "target_text = fra_tokenizer.texts_to_sequences(lines.fra)\n",
        "target_text[:3]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 19, 5, 1, 31, 11],\n",
              " [10, 15, 5, 12, 16, 29, 2, 14, 11],\n",
              " [10, 26, 9, 8, 28, 2, 1, 31, 11]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2SPvwmz7oiR",
        "outputId": "95b5b9a4-bede-4d40-94e4-6bba361fd81b"
      },
      "source": [
        "# 단어장 크기 출력\n",
        "\n",
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
        "# 0번 토큰 고려하여 + 1\n",
        "\n",
        "print(f\"영어 단어장의 크기 : {eng_vocab_size}\")\n",
        "print(f\"프랑스어 단어장의 크기 : {fra_vocab_size}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 단어장의 크기 : 52\n",
            "프랑스어 단어장의 크기 : 73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7MNq2qE7z0P",
        "outputId": "120e8fa6-5219-4b7e-9712-88c4f43e8b20"
      },
      "source": [
        "# 영어 데이터와 프랑스어 데이터의 최대길이\n",
        "# 패딩하기 위함\n",
        "\n",
        "max_eng_seq_len = max([len(line) for line in input_text])\n",
        "max_fra_seq_len = max([len(line) for line in target_text])\n",
        "\n",
        "print(f\"영어 시퀀스의 최대 길이 : {max_eng_seq_len}\")\n",
        "print(f\"프랑스어 시퀀스의 최대 길이 : {max_fra_seq_len}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 시퀀스의 최대 길이 : 22\n",
            "프랑스어 시퀀스의 최대 길이 : 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSehjcFq8X2b",
        "outputId": "835ab633-b81e-4dbf-abf6-03c394ef3460"
      },
      "source": [
        "# 전체적인 정보 한 번에 출력\n",
        "\n",
        "print(f\"전체 샘플의 수 : {len(lines)}\")\n",
        "print(f\"영어 단어장의 크기 : {eng_vocab_size}\")\n",
        "print(f\"프랑스어 단어장의 크기 : {fra_vocab_size}\")\n",
        "print(f\"영어 시퀀스의 최대 길이 : {max_eng_seq_len}\")\n",
        "print(f\"프랑스어 시퀀스의 최대 길이 : {max_fra_seq_len}\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수 : 50000\n",
            "영어 단어장의 크기 : 52\n",
            "프랑스어 단어장의 크기 : 73\n",
            "영어 시퀀스의 최대 길이 : 22\n",
            "프랑스어 시퀀스의 최대 길이 : 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ6bJPMa8sS_"
      },
      "source": [
        "encoder_input = input_text\n",
        "\n",
        "# 종료 토큰 제거\n",
        "decoder_input = [[char for char in line if char != fra_tokenizer.word_index[eos_token]] for line in target_text]\n",
        "\n",
        "# 시작 토큰 제거\n",
        "decoder_target = [[char for char in line if char != fra_tokenizer.word_index[sos_token]] for line in target_text]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phnP9Mc-9UE_",
        "outputId": "83effae5-f9f2-43b7-c57d-202e8cc72cc1"
      },
      "source": [
        "print(decoder_input[:3])\n",
        "# <eos> 토큰 제거\n",
        "\n",
        "print(decoder_input[:3])\n",
        "# <sos> 토큰 제거"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10, 19, 5, 1, 31], [10, 15, 5, 12, 16, 29, 2, 14], [10, 26, 9, 8, 28, 2, 1, 31]]\n",
            "[[10, 19, 5, 1, 31], [10, 15, 5, 12, 16, 29, 2, 14], [10, 26, 9, 8, 28, 2, 1, 31]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRkuh-FF-OU0",
        "outputId": "5ff5073b-093d-4060-fa24-d253fe02f920"
      },
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_eng_seq_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_fra_seq_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_fra_seq_len, padding='post')\n",
        "\n",
        "print('영어 데이터의 크기(shape) :', np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기 : ', np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기 : ', np.shape(decoder_target))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 데이터의 크기(shape) : (50000, 22)\n",
            "프랑스어 입력데이터의 크기 :  (50000, 74)\n",
            "프랑스어 출력데이터의 크기 :  (50000, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEGTbI7z-zC2",
        "outputId": "38caddf5-8643-4e39-dbea-69d9c05b6636"
      },
      "source": [
        "print(encoder_input[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19  3  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNDO41ng-03F",
        "outputId": "4c79d56e-739a-4e07-ee42-83d48b417bc8"
      },
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)\n",
        "\n",
        "print('영어 데이터의 크기 :', np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기 : ', np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기 :', np.shape(decoder_target)) #샘플의 수 x 샘플의 길이 x 단어장의 크기"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 데이터의 크기 : (50000, 22, 52)\n",
            "프랑스어 입력데이터의 크기 :  (50000, 74, 73)\n",
            "프랑스어 출력데이터의 크기 : (50000, 74, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVvsL_SR-2Gn",
        "outputId": "13ab057c-e09f-4800-9a43-74a3840d8f83"
      },
      "source": [
        "n_of_val = 3000\n",
        "\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]\n",
        "\n",
        "print(f\"영어 학습데이터의 크기 : {np.shape(encoder_input)}\")\n",
        "print(f\"프랑스어 학습 입력데이터의 크기 : {np.shape(decoder_input)}\")\n",
        "print(f\"프랑스어 학습 출력데이터의 크기 : {np.shape(decoder_target)}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 학습데이터의 크기 : (50000, 22, 52)\n",
            "프랑스어 학습 입력데이터의 크기 : (50000, 74, 73)\n",
            "프랑스어 학습 출력데이터의 크기 : (50000, 74, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLtpEI2q_1p8"
      },
      "source": [
        "## 모델 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1gYSW65_57Q"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfEJDJN5AC3K"
      },
      "source": [
        "# LSTM 셀의 마지막 time step의 hidden state와 cell state를 디코더 LSTM의 첫번째 hidden sate와 cell state로 전달\n",
        "\n",
        "encoder_inputs = Input(shape = (None, eng_vocab_size))\n",
        "# 입력 텐서 생성\n",
        "encoder_lstm = LSTM(units = 256, return_state = True)\n",
        "# hidden state 256인 LSTM 생성\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "# 디코더로 저달할 hidden state, cell state를 리턴. encoder_output은 여기서는 불필요함\n",
        "encoder_states = [state_h, state_c]\n",
        "# hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도로 저장"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NK_VPZtAymU"
      },
      "source": [
        "# 디코더 생성\n",
        "\n",
        "decoder_inputs = Input(shape = (None, fra_vocab_size))\n",
        "# 입력 텐서 생성\n",
        "decoder_lstm = LSTM(units = 256, return_sequences = True, return_state = True)\n",
        "# hidden state size 256 디코더 LSTM 생성\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
        "# decoder output은 모든 timestep의 hidden state \n",
        "# initial state : 초기상태"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ2ngn0bBjqB"
      },
      "source": [
        "decoder_softmax_layer = Dense(fra_vocab_size, activation = \"softmax\")\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4VtZ1psCFTJ",
        "outputId": "e389ede2-0e7a-48e2-b914-1080f13195be"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], [decoder_outputs])\n",
        "model.compile(optimizer = \"rmsprop\", loss = \"categorical_crossentropy\")\n",
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 52)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 73)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 256), (None, 316416      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  337920      input_2[0][0]                    \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 73)     18761       lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 673,097\n",
            "Trainable params: 673,097\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBMwwBZXCj6J",
        "outputId": "4a4f09a5-2ec6-4091-8022-8eaf9737c98e"
      },
      "source": [
        "model.fit(x = [encoder_input_train, decoder_input_train], \n",
        "          y = decoder_target_train, \n",
        "          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test), \n",
        "          batch_size = 128, epochs = 30)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "368/368 [==============================] - 16s 21ms/step - loss: 0.9058 - val_loss: 0.8049\n",
            "Epoch 2/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.5674 - val_loss: 0.6599\n",
            "Epoch 3/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.4705 - val_loss: 0.5678\n",
            "Epoch 4/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.4143 - val_loss: 0.5169\n",
            "Epoch 5/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.3755 - val_loss: 0.4928\n",
            "Epoch 6/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.3468 - val_loss: 0.4495\n",
            "Epoch 7/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.3251 - val_loss: 0.4330\n",
            "Epoch 8/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.3079 - val_loss: 0.4152\n",
            "Epoch 9/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2940 - val_loss: 0.4067\n",
            "Epoch 10/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.2822 - val_loss: 0.3913\n",
            "Epoch 11/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.2723 - val_loss: 0.3888\n",
            "Epoch 12/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.2633 - val_loss: 0.3788\n",
            "Epoch 13/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2553 - val_loss: 0.3725\n",
            "Epoch 14/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.2482 - val_loss: 0.3714\n",
            "Epoch 15/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2415 - val_loss: 0.3672\n",
            "Epoch 16/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2356 - val_loss: 0.3661\n",
            "Epoch 17/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.2300 - val_loss: 0.3650\n",
            "Epoch 18/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2251 - val_loss: 0.3686\n",
            "Epoch 19/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2202 - val_loss: 0.3599\n",
            "Epoch 20/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.2157 - val_loss: 0.3595\n",
            "Epoch 21/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.2115 - val_loss: 0.3588\n",
            "Epoch 22/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.2075 - val_loss: 0.3594\n",
            "Epoch 23/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.2037 - val_loss: 0.3581\n",
            "Epoch 24/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.2000 - val_loss: 0.3655\n",
            "Epoch 25/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.1966 - val_loss: 0.3564\n",
            "Epoch 26/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.1933 - val_loss: 0.3619\n",
            "Epoch 27/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.1903 - val_loss: 0.3581\n",
            "Epoch 28/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.1871 - val_loss: 0.3613\n",
            "Epoch 29/30\n",
            "368/368 [==============================] - 7s 19ms/step - loss: 0.1843 - val_loss: 0.3642\n",
            "Epoch 30/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.1814 - val_loss: 0.3648\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fec6c200610>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za4yIP0FDIVq"
      },
      "source": [
        "## 모델 테스트\n",
        "훈련시 학습해야할 타겟 문장을 디코더 모델의 입/출력 시퀀스로 넣어주고, 디코더 모델이 타겟문장을 한꺼번에 출력하게 할 수 있음. 테스트 단계는 불가능<br><br>\n",
        "\n",
        "테스트 단계에서 디코더 동작 순서\n",
        "- 인라인에 입력 문장을 넣어 마지막 time step의 hidden/cell state를 얻음\n",
        "- 토큰인 \\t를 디코더에 입력\n",
        "- 이전 time step의 출력층의 예측결과를 현재 timestep의 입력으로 함\n",
        "- 3을 반복하다가 토큰인 \\n이 예측되면 이를 중단"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQH9-drfGtm0",
        "outputId": "d9766d37-39ec-4dcc-b0ba-3bf84a2c6b28"
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
        "encoder_model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 52)]        0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  [(None, 256), (None, 256) 316416    \n",
            "=================================================================\n",
            "Total params: 316,416\n",
            "Trainable params: 316,416\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBeW9S9FGxnS"
      },
      "source": [
        "decoder_state_input_h = Input(shape = (256, ))\n",
        "# 이전 time step의 hidden state를 저장하는 텐서\n",
        "decoder_state_input_c = Input(shape = (256,))\n",
        "# 이전 timestep의 cell state를 저장하는 텐서\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "\n",
        "# decoder_state_inputs를 현재 time step의 초기상태로 사용\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state = decoder_state_inputs)\n",
        "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "decoder_states = [state_h, state_c]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_13SntKHIrW",
        "outputId": "5548212c-dbd7-43a3-dd56-16df08d1b15a"
      },
      "source": [
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model= Model(inputs = [decoder_inputs] + decoder_state_inputs, outputs = [decoder_outputs] + decoder_states)\n",
        "decoder_model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 73)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  337920      input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 73)     18761       lstm_1[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 356,681\n",
            "Trainable params: 356,681\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Cf3SDnH1zl"
      },
      "source": [
        "eng2idx = eng_tokenizer.word_index\n",
        "fra2idx = fra_tokenizer.word_index\n",
        "idx2eng = eng_tokenizer.index_word\n",
        "idx2fra = fra_tokenizer.index_word"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B16U0T2GIScn"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "  target_seq = np.zeros((1, 1, fra_vocab_size))\n",
        "  target_seq[0, 0, fra2idx['\\t']] =1\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  # stop condition이 True가 될떄까지 루프 반복\n",
        "  while not stop_condition:\n",
        "    # 이전 시점의 상태 state_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq]+ states_value)\n",
        "\n",
        "    # 예측 결과를 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = idx2fra[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 최대 길이를 넘으면 중단\n",
        "    if (sampled_char == '\\n' or\n",
        "        len(decoded_sentence) > max_fra_seq_len):\n",
        "      stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1, 1, fra_vocab_size))\n",
        "    target_seq[0, 0, sampled_token_index] =1\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "  return decoded_sentence"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtrBQtCJJMeq",
        "outputId": "b3019099-0f4a-40d1-c8d4-15bbf497cc77"
      },
      "source": [
        "import numpy as np\n",
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  # 입력 문장의 인덱스 (자유롭게 바꿔서 테스트 해보세요!)\n",
        "  input_seq = encoder_input[seq_index: seq_index +1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * \"-\")\n",
        "  print('입력 문장 :', lines.eng[seq_index])\n",
        "  print('정답 문장 :', lines.fra[seq_index][1:len(lines.fra[seq_index])-1])\n",
        "  # '\\t'와 '\\n'을 빼고 출력\n",
        "  print('번역기가 번역한 문장 :', decoded_sentence[:len(decoded_sentence)-1])\n",
        "  # '\\n'을 빼고 출력"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "입력 문장 : Hi.\n",
            "정답 문장 : Salut !\n",
            "번역기가 번역한 문장 : salut !\n",
            "-----------------------------------\n",
            "입력 문장 : I won!\n",
            "정답 문장 : Je l'ai emporté !\n",
            "번역기가 번역한 문장 : j'ai besoin !\n",
            "-----------------------------------\n",
            "입력 문장 : I fled.\n",
            "정답 문장 : J'ai fui.\n",
            "번역기가 번역한 문장 : je suis préparée.\n",
            "-----------------------------------\n",
            "입력 문장 : Hug Tom.\n",
            "정답 문장 : Fais un câlin à Tom.\n",
            "번역기가 번역한 문장 : sagez-le.\n",
            "-----------------------------------\n",
            "입력 문장 : I give in.\n",
            "정답 문장 : Je donne ma langue au chat.\n",
            "번역기가 번역한 문장 : j'ai déjà.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "521HMfDXJ327"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}