{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP3.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rRYF_Q04mjl9",
        "SsdPR_tPoSeF",
        "jjkl-6OhprqK",
        "nmoS01qtqFsj",
        "tKa1wF-7sP-E",
        "l2hMG92dtJZJ",
        "szkIlKkgwWQj",
        "dX8DIhrJxfLI"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oclJnR-7mkjF"
      },
      "source": [
        "2021-06-11<br><br>\n",
        "\n",
        "NLP 강의 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRYF_Q04mjl9"
      },
      "source": [
        "## Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHjrdk1Km0Cg"
      },
      "source": [
        "# 전처리 과정에서 문자를 숫자로 벡터화 해왔음\n",
        "# 1. 통계와 머신러닝 활용한 방법\n",
        "# 2. 인공신경망을 활용한 방법\n",
        "\n",
        "# BOW\n",
        "# 문서들을 단어들의 가방으로 가장하느것\n",
        "# 단어 순서무시. 전부 섞임\n",
        "# 중복제거X\n",
        "# 빈도 정보 그대로 존재\n",
        "\n",
        "# doc1 = 'John likes to watch movies. Mary likes movies too.'\n",
        "\n",
        "# BoW1 = {\"John\":1, \"likes\":2, \"to\":1, \"watch\":1, \"movies\":2, \"Mary\":1, \"too\":1}\n",
        "\n",
        "\n",
        "# doc2 = 'Mary also likes to watch football games.'  \n",
        "# BoW2 = {\"Mary\":1, \"also\":1, \"likes\":1, \"to\":1, \"watch\":1, \"football\":1, \"games\":1}\n",
        "\n",
        "\n",
        "# doc3 = 'John likes to watch movies. Mary likes movies too. Mary also likes to watch football games.'\n"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsdPR_tPoSeF"
      },
      "source": [
        "## keras Tokenizer를 이용한 BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1YisiBhoa2K"
      },
      "source": [
        "# import\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAuhvNVoogyW"
      },
      "source": [
        "# 사용할 문장\n",
        "\n",
        "sentence = ['John likes to watch movies. Mary likes movies too. Mary also likes to watch football games.']"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euHMmYZZonbj",
        "outputId": "4bb45b12-5ca8-4c3d-b038-61b9cccbfb96"
      },
      "source": [
        "def print_bow(sentence):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(sentence)   \n",
        "  # 단어장 생성\n",
        "  bow = dict(tokenizer.word_counts)\n",
        "  # 각 단어와 각 단어의 빈도를 bow에 저장\n",
        "\n",
        "  print(\"Bag of words :\", bow)\n",
        "  print(\"단어장(vocabulary)의 크기 :\", len(tokenizer.word_counts))\n",
        "  #중복 제거한 단어의 갯수\n",
        "\n",
        "print_bow(sentence)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bag of words : {'john': 1, 'likes': 3, 'to': 2, 'watch': 2, 'movies': 2, 'mary': 2, 'too': 1, 'also': 1, 'football': 1, 'games': 1}\n",
            "단어장(vocabulary)의 크기 : 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjkl-6OhprqK"
      },
      "source": [
        "## scikit-learn CountVectorizer활용한 BOW"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64rOdHXkpKPi"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONAp4Lyyp0rK"
      },
      "source": [
        "sentence = [\"John likes to watch movies. Mary likes movies too! Mary also likes to watch football games.\"]"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGsgTvnJp1ij",
        "outputId": "6912c5eb-e27d-47c6-9b7b-3a51a1f610b2"
      },
      "source": [
        "vector = CountVectorizer()\n",
        "\n",
        "print(\"Bag of Words : \", vector.fit_transform(sentence).toarray())\n",
        "# 코퍼스로부터 각 단어의 빈도수를 기록\n",
        "\n",
        "print(\"각 단어의 인덱스 :\", vector.vocabulary_)\n",
        "# 각 단어의 인덱스가 어떻게 부여되었는지 보여줌\n",
        "\n",
        "print(\"단어장(vocabulary)의 크기 :\", len(vector.vocabulary_))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bag of Words :  [[1 1 1 1 3 2 2 2 1 2]]\n",
            "각 단어의 인덱스 : {'john': 3, 'likes': 4, 'to': 7, 'watch': 9, 'movies': 6, 'mary': 5, 'too': 8, 'also': 0, 'football': 1, 'games': 2}\n",
            "단어장(vocabulary)의 크기 : 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmoS01qtqFsj"
      },
      "source": [
        "##DTM(Documnet-Term Matrix)\n",
        "\n",
        "TDM이라고 하는 경우도 있음\n",
        "\n",
        "문서 1 : I like dog<br>\n",
        "문서 2 : I like cat<br>\n",
        "문서 3 : I like cat I like cat<br><br>\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th></th><th>cat</th><th>dog</th><th>I</th><th>like</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>문서1</td><td>0</td><td>1</td><td>1</td><td>1</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>문서2</td><td>1</td><td>0</td><td>1</td><td>1</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>문서3</td><td>2</td><td>0</td><td>2</td><td>2</td>\n",
        "  </tr>\n",
        "</table>       "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaKGzgdkqy53"
      },
      "source": [
        "import numpy as np\n",
        "from numpy import dot \n",
        "from numpy.linalg import norm\n",
        "\n",
        "doc1 = np.array([0, 1, 1, 1])\n",
        "doc2 = np.array([1, 0, 1, 1])\n",
        "doc3 = np.array([2, 0, 2, 2])\n",
        "\n",
        "def cos_sim(A, B):\n",
        "  return dot(A, B)/(norm(A)*norm(B))"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtd-s0RGsPfi",
        "outputId": "38be9cc4-a443-47ac-f5e7-5f6f135f2f94"
      },
      "source": [
        "# 코사인 유사도 계산\n",
        "\n",
        "print(cos_sim(doc1, doc2)) \n",
        "print(cos_sim(doc1, doc3))\n",
        "print(cos_sim(doc2, doc3))\n",
        "\n",
        "# DTM에서는 코사인 유사도는 0이상 1이하의 값을 가지고, 값이 1에 가까울수록 유사도 높다 판단"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6666666666666667\n",
            "0.6666666666666667\n",
            "1.0000000000000002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKa1wF-7sP-E"
      },
      "source": [
        "## scikit-learn CountVectorizer활용한 DTM구현\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_Fx5CoYsbA0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8e3504f-d507-4299-ad7f-bca3db01e094"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "corpus = [\n",
        "          'John likes to watch movies',\n",
        "          'Mary likes movies too',\n",
        "          'Mary also likes to watch football games',\n",
        "]\n",
        "\n",
        "vector = CountVectorizer()\n",
        "print(vector.fit_transform(corpus).toarray())\n",
        "# 코퍼스로부터 각 단어의 빈도수 기록\n",
        "print(vector.vocabulary_)\n",
        "# 각 단어의 인덱스가 어떻게 부여되었는지 출력\n",
        "\n",
        "# 단어수가 늘 수록 0이 많아짐(spharse)\n",
        "# 단어 빈도수에만 치중하는 경향이 있음\n",
        "# 중요성을 알 수 없음"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 1 1 0 1 1 0 1]\n",
            " [0 0 0 0 1 1 1 0 1 0]\n",
            " [1 1 1 0 1 1 0 1 0 1]]\n",
            "{'john': 3, 'likes': 4, 'to': 7, 'watch': 9, 'movies': 6, 'mary': 5, 'too': 8, 'also': 0, 'football': 1, 'games': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2hMG92dtJZJ"
      },
      "source": [
        "## TF-IDF\n",
        "DTM의 위와 같은 한계점 때문에 TF-IDF가 등장<br>\n",
        "모든 문서에서 자주 등장하는 단어는 중요도가 낮다고 판단<br>\n",
        "특정 문서에서만 자주 등장하는 단어는 중요도가 높다고 판단<br><br>\n",
        "\n",
        "TF-IDF를 사용한 결과가 DTM보다 무조건 좋지는 않음<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_LoNak5tJE9"
      },
      "source": [
        "# import\n",
        "\n",
        "from math import log\n",
        "import pandas as pd"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSDOKkkHtI-3"
      },
      "source": [
        "docs = [\n",
        "        'John likes to watch movies and Mary likes movies too',\n",
        "        'James likes to watch TV',\n",
        "        'Mary also likes to watch football games',\n",
        "]"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7CypqF0ntI-K",
        "outputId": "c80d2961-b9ca-4446-c1b8-3c486c4683c9"
      },
      "source": [
        "# 단어장 생성\n",
        "\n",
        "vocab = list(set(w for doc in docs for w in doc.split()))\n",
        "vocab.sort()\n",
        "\n",
        "print(\"단어장의 크기 :\", len(vocab))\n",
        "print(vocab)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어장의 크기 : 13\n",
            "['James', 'John', 'Mary', 'TV', 'also', 'and', 'football', 'games', 'likes', 'movies', 'to', 'too', 'watch']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yx2soUetI59",
        "outputId": "e23218a3-d76b-4063-8398-2b0f048a67e3"
      },
      "source": [
        "# 문서(문장)의 수\n",
        "\n",
        "n = len(docs)\n",
        "n"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN7U1p_eupNR"
      },
      "source": [
        "# TF-IDF 구현\n",
        "\n",
        "def tf(t, d):\n",
        "  return d.count(t)\n",
        "\n",
        "def idf(t):\n",
        "  df = 0\n",
        "  for doc in docs:\n",
        "    df += t in doc\n",
        "\n",
        "  return log(n / (df + 1)) + 1\n",
        "\n",
        "def tfidf(t, d):\n",
        "  return tf(t, d) * idf(t)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "e7O12eb5vFCa",
        "outputId": "fc48abc9-8aa5-4c8c-f7d4-02a962182f1a"
      },
      "source": [
        "# tf 함수를 사용하여 DTM 생성\n",
        "\n",
        "result = []\n",
        "\n",
        "for i in range(n):\n",
        "  result.append([])\n",
        "  d = docs[i]\n",
        "  for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "\n",
        "    result[-1].append(tf(t, d))\n",
        "\n",
        "tf_ = pd.DataFrame(result, columns=vocab)\n",
        "tf_"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>James</th>\n",
              "      <th>John</th>\n",
              "      <th>Mary</th>\n",
              "      <th>TV</th>\n",
              "      <th>also</th>\n",
              "      <th>and</th>\n",
              "      <th>football</th>\n",
              "      <th>games</th>\n",
              "      <th>likes</th>\n",
              "      <th>movies</th>\n",
              "      <th>to</th>\n",
              "      <th>too</th>\n",
              "      <th>watch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   James  John  Mary  TV  also  and  ...  games  likes  movies  to  too  watch\n",
              "0      0     1     1   0     0    1  ...      0      2       2   2    1      1\n",
              "1      1     0     0   1     0    0  ...      0      1       0   1    0      1\n",
              "2      0     0     1   0     1    0  ...      1      1       0   1    0      1\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "U-VDih6Avi8S",
        "outputId": "697e1de9-a5dc-4fcc-904b-4976428ee602"
      },
      "source": [
        "# idf\n",
        "\n",
        "result = []\n",
        "\n",
        "for j in range(len(vocab)):\n",
        "  t = vocab[j]\n",
        "  result.append(idf(t))\n",
        "\n",
        "idf_ = pd.DataFrame(result, index = vocab, columns = [\"IDF\"])\n",
        "idf_"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>James</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>John</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mary</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TV</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>also</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>and</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>football</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>games</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>likes</th>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movies</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>to</th>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>too</th>\n",
              "      <td>1.405465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>watch</th>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               IDF\n",
              "James     1.405465\n",
              "John      1.405465\n",
              "Mary      1.000000\n",
              "TV        1.405465\n",
              "also      1.405465\n",
              "and       1.405465\n",
              "football  1.405465\n",
              "games     1.405465\n",
              "likes     0.712318\n",
              "movies    1.405465\n",
              "to        0.712318\n",
              "too       1.405465\n",
              "watch     0.712318"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TmouSnlwv7AZ",
        "outputId": "fb26de2b-7829-4f85-d039-ab624a0ebd7a"
      },
      "source": [
        "# tf-idf 행렬 출력\n",
        "# 각 단어의 tf에 IDF 곱해준값\n",
        "\n",
        "result = []\n",
        "\n",
        "for i in range(n):\n",
        "  result.append([])\n",
        "  d = docs[i]\n",
        "  for j in range(len(vocab)):\n",
        "    t = vocab[j]\n",
        "\n",
        "    result[-1].append(tfidf(t, d))\n",
        "\n",
        "tfidf_ = pd.DataFrame(result, columns = vocab)\n",
        "tfidf_"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>James</th>\n",
              "      <th>John</th>\n",
              "      <th>Mary</th>\n",
              "      <th>TV</th>\n",
              "      <th>also</th>\n",
              "      <th>and</th>\n",
              "      <th>football</th>\n",
              "      <th>games</th>\n",
              "      <th>likes</th>\n",
              "      <th>movies</th>\n",
              "      <th>to</th>\n",
              "      <th>too</th>\n",
              "      <th>watch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.424636</td>\n",
              "      <td>2.81093</td>\n",
              "      <td>1.424636</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.712318</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.712318</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>1.405465</td>\n",
              "      <td>0.712318</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.712318</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.712318</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      James      John  Mary        TV  ...   movies        to       too     watch\n",
              "0  0.000000  1.405465   1.0  0.000000  ...  2.81093  1.424636  1.405465  0.712318\n",
              "1  1.405465  0.000000   0.0  1.405465  ...  0.00000  0.712318  0.000000  0.712318\n",
              "2  0.000000  0.000000   1.0  0.000000  ...  0.00000  0.712318  0.000000  0.712318\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szkIlKkgwWQj"
      },
      "source": [
        "## scikit-learn TFidVectorizer 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gz-OWF7w2oP"
      },
      "source": [
        "# import \n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K96zEwWFw9iJ"
      },
      "source": [
        "# data\n",
        "\n",
        "corpus = [\n",
        "          \"John I likes to watch movies and Mary I likes movies too\",\n",
        "          \"James likes to watch TV\",\n",
        "          \"Mary also likes to watch football games\",\n",
        "]"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "b3p_DegBxJiA",
        "outputId": "466cdc96-67fd-40cd-8d1f-f4687e783404"
      },
      "source": [
        "tfidfv = TfidfVectorizer().fit(corpus)\n",
        "vocab = list(set(tfidfv.vocabulary_.keys()))\n",
        "vocab.sort()\n",
        "\n",
        "tfidf_ = pd.DataFrame(tfidfv.transform(corpus).toarray(), columns = vocab)\n",
        "tfidf_"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>also</th>\n",
              "      <th>and</th>\n",
              "      <th>football</th>\n",
              "      <th>games</th>\n",
              "      <th>james</th>\n",
              "      <th>john</th>\n",
              "      <th>likes</th>\n",
              "      <th>mary</th>\n",
              "      <th>movies</th>\n",
              "      <th>to</th>\n",
              "      <th>too</th>\n",
              "      <th>tv</th>\n",
              "      <th>watch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.321556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.321556</td>\n",
              "      <td>0.379832</td>\n",
              "      <td>0.244551</td>\n",
              "      <td>0.643111</td>\n",
              "      <td>0.189916</td>\n",
              "      <td>0.321556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.189916</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.572929</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.338381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.338381</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.572929</td>\n",
              "      <td>0.338381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.464997</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.464997</td>\n",
              "      <td>0.464997</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.274634</td>\n",
              "      <td>0.353642</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.274634</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.274634</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       also       and  football  ...       too        tv     watch\n",
              "0  0.000000  0.321556  0.000000  ...  0.321556  0.000000  0.189916\n",
              "1  0.000000  0.000000  0.000000  ...  0.000000  0.572929  0.338381\n",
              "2  0.464997  0.000000  0.464997  ...  0.000000  0.000000  0.274634\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX8DIhrJxfLI"
      },
      "source": [
        "## LSA, LDA\n",
        "\n",
        "이전까지는 bag of word 기반<br>\n",
        "의미 주제 알고싶지만 이전모델로는 표현 불가했음<br>\n",
        "이를 해결하기위해 LSA, LDA 가 등장<br><br>\n",
        "\n",
        "단어와 단어사이 문장과 문장사이 유사성 <br>\n",
        "효과적인게 많음<br><br>\n",
        "\n",
        "LSA :<br>\n",
        "전체 코퍼스에서 문자 속 단어들의 상의 관계를 찾아낸느 자연어 처리 정보탐색 기술<br>\n",
        "단어와 단어 사이, 문서와 문서 사이, 단어와 문장 사이 유사성 점수를 찾아냄<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAq7HoeX1_yc"
      },
      "source": [
        "# import\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bg5HRPcF3REA",
        "outputId": "7e706a62-0673-4268-ca95-9bf14b41b3ca"
      },
      "source": [
        "! pip install nltk"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekB6uLw33VDb",
        "outputId": "b929f008-2c0d-42eb-be91-6d5712a6b25c"
      },
      "source": [
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tswY0Ck3adE",
        "outputId": "2199a19a-ac41-49a1-88c9-b1ab0f3f147b"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCZpO33E5-XU",
        "outputId": "bc0af990-fcac-4772-92eb-10c00cf7a65e"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/franciscadias/data/master/abcnews-date-text.csv\",\n",
        "                           filename=\"/content/abcnews-data-text.csv\")"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/abcnews-data-text.csv', <http.client.HTTPMessage at 0x7f42c708f290>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3LJzzkNT5_zq"
      },
      "source": [
        "data = pd.read_csv('/content/abcnews-data-text.csv', error_bad_lines=False)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "kw-eGgHh6BVs",
        "outputId": "0e9dd9c4-3f0a-4372-c1e0-5310a3ce5844"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>publish_date</th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20030219</td>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20030219</td>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20030219</td>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20030219</td>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20030219</td>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   publish_date                                      headline_text\n",
              "0      20030219  aba decides against community broadcasting lic...\n",
              "1      20030219     act fire witnesses must be aware of defamation\n",
              "2      20030219     a g calls for infrastructure protection summit\n",
              "3      20030219           air nz staff in aust strike for pay rise\n",
              "4      20030219      air nz strike to affect australian travellers"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Eq2Q_o7u6DQI",
        "outputId": "b4a08c75-c362-4b30-a230-8b2dfb625f70"
      },
      "source": [
        "text = data [[\"headline_text\"]]\n",
        "text.head()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aba decides against community broadcasting lic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>act fire witnesses must be aware of defamation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a g calls for infrastructure protection summit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>air nz staff in aust strike for pay rise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>air nz strike to affect australian travellers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       headline_text\n",
              "0  aba decides against community broadcasting lic...\n",
              "1     act fire witnesses must be aware of defamation\n",
              "2     a g calls for infrastructure protection summit\n",
              "3           air nz staff in aust strike for pay rise\n",
              "4      air nz strike to affect australian travellers"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh-ib4nU6IhL",
        "outputId": "6a577116-ac5f-4f40-e767-ba14b092a56e"
      },
      "source": [
        "text.nunique()\n",
        "\n",
        "# 3만개 가량이 중복데이터였음"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "headline_text    1054983\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiv1cQxU6Prl",
        "outputId": "d0f9e58a-a215-4d3f-f4c1-4d06ebe39e31"
      },
      "source": [
        "# 중복 제거\n",
        "\n",
        "text.drop_duplicates(inplace = True)\n",
        "text = text.reset_index(drop = True)\n",
        "\n",
        "print(len(text))"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1054983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhwQca_76sTi"
      },
      "source": [
        "### 데이터 정제 및 정규화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMTv5yfC6wK9"
      },
      "source": [
        "# NLTK 토크나이저를 이용해 토큰화\n",
        "\n",
        "text[\"headline_text\"] = text.apply(lambda row: nltk.word_tokenize(row[\"headline_text\"]), axis = 1)"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTMQ-OaF65gG"
      },
      "source": [
        "# 불용어 제거\n",
        "\n",
        "stop_words = stopwords.words(\"english\")\n",
        "text[\"headline_text\"] = text[\"headline_text\"].apply(lambda x: [word for word in x if word not in (stop_words)])"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wwf8Ebru7iA-",
        "outputId": "86faa8f6-f6fc-461b-f6cd-02b314d46836"
      },
      "source": [
        "text.head()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[aba, decides, community, broadcasting, licence]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[act, fire, witnesses, must, aware, defamation]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[g, calls, infrastructure, protection, summit]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[air, nz, staff, aust, strike, pay, rise]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[air, nz, strike, affect, australian, travellers]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       headline_text\n",
              "0   [aba, decides, community, broadcasting, licence]\n",
              "1    [act, fire, witnesses, must, aware, defamation]\n",
              "2     [g, calls, infrastructure, protection, summit]\n",
              "3          [air, nz, staff, aust, strike, pay, rise]\n",
              "4  [air, nz, strike, affect, australian, travellers]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QvlzT-z7tVp"
      },
      "source": [
        "# 단어 정규화 과정 \n",
        "# 길이가 1~2인 단어는 제거하는 전처리 과정임\n",
        "# 단어 정규화 \n",
        "# 3인칭 단수 표현 .> 1인칭 변환, 과거형 동사 -> 현재형 동사\n",
        "# 등을 수행\n",
        "\n",
        "text[\"headline_text\"] = text[\"headline_text\"].apply(lambda x: [WordNetLemmatizer().lemmatize(word, pos = \"v\") for word in x])"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JqCE0M774eJ",
        "outputId": "fe98c649-035c-49bf-bdf6-b59129b17ae2"
      },
      "source": [
        "# 길이가 1~2인 단어를 제거\n",
        "\n",
        "text = text[\"headline_text\"].apply(lambda x: [word for word in x if len(word) > 2])\n",
        "\n",
        "print(text[:5])"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0     [aba, decide, community, broadcast, licence]\n",
            "1    [act, fire, witness, must, aware, defamation]\n",
            "2       [call, infrastructure, protection, summit]\n",
            "3            [air, staff, aust, strike, pay, rise]\n",
            "4    [air, strike, affect, australian, travellers]\n",
            "Name: headline_text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RT8lMzkY8jdL"
      },
      "source": [
        "# 역토큰화 \n",
        "# 토큰화 작업을 역으로 수행\n",
        "\n",
        "detokenized_doc=[]\n",
        "\n",
        "for i in range(len(text)):\n",
        "  t = ' '.join(text[i])\n",
        "  detokenized_doc.append(t)\n",
        "\n",
        "train_data = detokenized_doc"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIBFIkwp9ElF",
        "outputId": "ae0f39a6-d817-4e0a-e7eb-982294291684"
      },
      "source": [
        "train_data[:5]"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['aba decide community broadcast licence',\n",
              " 'act fire witness must aware defamation',\n",
              " 'call infrastructure protection summit',\n",
              " 'air staff aust strike pay rise',\n",
              " 'air strike affect australian travellers']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvgzuiKj9Ito"
      },
      "source": [
        "# 상위 5000개 단어만 사용\n",
        "\n",
        "c_vectorizer = CountVectorizer(stop_words = \"english\", max_features = 5000)\n",
        "document_term_matrix = c_vectorizer.fit_transform(train_data)"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwHG4tG99Zsh",
        "outputId": "e9c84998-d23e-41f5-a4fd-58287a7a12af"
      },
      "source": [
        "# DTM의 크기\n",
        "\n",
        "print('행렬의 크기 : ', document_term_matrix.shape) \n",
        "# 문서의 수 X 단어 집합의 크기"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "행렬의 크기 :  (1054983, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3irVHi19urf"
      },
      "source": [
        "## scikit-learn Truncated SVD 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWu2RP4n-QGZ",
        "outputId": "77944b0a-0de0-4879-9e74-9842f3c683a3"
      },
      "source": [
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "n_topics = 10\n",
        "lsa_model = TruncatedSVD(n_components = n_topics)\n",
        "lsa_model.fit_transform(document_term_matrix)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.01208312, -0.00347201,  0.0182566 , ...,  0.00286796,\n",
              "         0.00124732,  0.01560101],\n",
              "       [ 0.0290736 , -0.01121828,  0.01829939, ..., -0.00148709,\n",
              "        -0.01215122, -0.00819526],\n",
              "       [ 0.00508009, -0.00175831,  0.00970242, ..., -0.00210328,\n",
              "         0.0017365 ,  0.0033025 ],\n",
              "       ...,\n",
              "       [ 0.02969598,  0.00370105,  0.0252737 , ...,  0.02216185,\n",
              "         0.00875934,  0.01866306],\n",
              "       [ 0.06334385, -0.00523409,  0.13847997, ...,  0.97840388,\n",
              "         0.79656213, -0.46934265],\n",
              "       [ 0.07122255,  0.03425599, -0.00121457, ...,  0.02998473,\n",
              "        -0.03229205,  0.04109267]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fmav4-iN-RSC",
        "outputId": "9e8da296-5afd-4b59-8519-576cef1f6800"
      },
      "source": [
        "print(np.shape(lsa_model.components_))"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giR1b1oN-UgF"
      },
      "source": [
        "terms = c_vectorizer.get_feature_names()\n",
        "\n",
        "def get_topics(components, feature_names, n=5):\n",
        "  for idx, topic in enumerate(components):\n",
        "    print(\"Topic %d:\" % (idx+1), [(feature_names[i], topic[i].round(5)) for i in topic.argsort()[:-n - 1:-1]])"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4Cs-PZK_EwZ",
        "outputId": "78de34d6-da0b-4a7a-ef76-c52e45587e1d"
      },
      "source": [
        "get_topics(lsa_model.components_, terms)\n",
        "\n",
        "# 새로운 정보 업데이트가 어려움\n",
        "# 다시 이 과정을 해야하기 때문"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Topic 1: [('police', 0.74641), ('man', 0.45354), ('charge', 0.21092), ('new', 0.14085), ('court', 0.11149)]\n",
            "Topic 2: [('man', 0.69458), ('charge', 0.29939), ('court', 0.16691), ('face', 0.1154), ('murder', 0.10679)]\n",
            "Topic 3: [('new', 0.83674), ('plan', 0.23653), ('say', 0.18282), ('govt', 0.11095), ('council', 0.1102)]\n",
            "Topic 4: [('say', 0.73915), ('plan', 0.36123), ('govt', 0.16366), ('council', 0.1274), ('urge', 0.07315)]\n",
            "Topic 5: [('plan', 0.73342), ('council', 0.17531), ('govt', 0.13674), ('urge', 0.08439), ('water', 0.0723)]\n",
            "Topic 6: [('govt', 0.51785), ('court', 0.26992), ('urge', 0.22922), ('nsw', 0.17207), ('face', 0.16695)]\n",
            "Topic 7: [('charge', 0.50032), ('court', 0.47566), ('face', 0.36637), ('plan', 0.11458), ('murder', 0.1094)]\n",
            "Topic 8: [('win', 0.65409), ('court', 0.28842), ('kill', 0.20107), ('crash', 0.18199), ('australia', 0.09986)]\n",
            "Topic 9: [('win', 0.56016), ('charge', 0.53357), ('australia', 0.09419), ('council', 0.08354), ('cup', 0.06226)]\n",
            "Topic 10: [('council', 0.64234), ('crash', 0.30306), ('kill', 0.28993), ('car', 0.11756), ('charge', 0.11629)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVZfba90Cq-0"
      },
      "source": [
        "# LDA\n",
        "\n",
        "# 역토큰화 과정을거친\n",
        "# 앞서 전처리해둔 train 데이터 사용할것임"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksFGGChoEVeI"
      },
      "source": [
        "TF-IDF 행렬 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_CzBmSgEV5e",
        "outputId": "c0571e0c-9e1b-4bfe-e286-92ecdd9baf56"
      },
      "source": [
        "# 상위 5000개의 단어만 사용\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_features = 5000)\n",
        "tf_idf_matrix = tfidf_vectorizer.fit_transform(train_data)\n",
        "\n",
        "# TF-IDF행렬의 크기를 확인\n",
        "print('행렬의 크기 : ', tf_idf_matrix.shape)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "행렬의 크기 :  (1054983, 5000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKUJFdABEYMg"
      },
      "source": [
        "scikit-learn LDA model활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e14lg_9mEW3N",
        "outputId": "80808234-44d7-4099-dedf-b68c6ce73125"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "lda_model = LatentDirichletAllocation(n_components = 10, learning_method = 'online', random_state = 777, max_iter=1)\n",
        "lda_model.fit_transform(tf_idf_matrix)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.0335099 , 0.0335099 , 0.0335099 , ..., 0.17024867, 0.0335099 ,\n",
              "        0.0335099 ],\n",
              "       [0.03365631, 0.03365631, 0.03365631, ..., 0.03365631, 0.03365631,\n",
              "        0.03365631],\n",
              "       [0.25184095, 0.0366096 , 0.0366096 , ..., 0.0366096 , 0.0366096 ,\n",
              "        0.0366096 ],\n",
              "       ...,\n",
              "       [0.26687206, 0.02914502, 0.02914502, ..., 0.13007484, 0.02916018,\n",
              "        0.28739608],\n",
              "       [0.10378115, 0.02637829, 0.12325014, ..., 0.02637829, 0.02637829,\n",
              "        0.02637829],\n",
              "       [0.03376055, 0.03376055, 0.2255442 , ..., 0.03376055, 0.03376055,\n",
              "        0.03376055]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAvZD6meEZRb"
      },
      "source": [
        "# word 2 vec"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGjWt9mq4SbW",
        "outputId": "3d4b82d7-069b-4fcf-ec89-6bdb8dc911b3"
      },
      "source": [
        "!pip install nltk\n",
        "!pip install gensim"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.0.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5fQeMsC4XWJ"
      },
      "source": [
        "# import \n",
        "\n",
        "import nltk"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-002j814ccU",
        "outputId": "2a256226-3ef2-4328-8589-6d960e8691fe"
      },
      "source": [
        "# nltk에서 필요한 것 다운로드\n",
        "\n",
        "nltk.download(\"abc\")\n",
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/abc.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlCjPdSM4juT"
      },
      "source": [
        "from nltk.corpus import abc"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "latXIYmE4ne7"
      },
      "source": [
        "corpus = abc.sents()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtSBqICM4ppF",
        "outputId": "a3797704-0f12-42e0-e682-f1a5d55bab47"
      },
      "source": [
        "print(corpus[:3])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['PM', 'denies', 'knowledge', 'of', 'AWB', 'kickbacks', 'The', 'Prime', 'Minister', 'has', 'denied', 'he', 'knew', 'AWB', 'was', 'paying', 'kickbacks', 'to', 'Iraq', 'despite', 'writing', 'to', 'the', 'wheat', 'exporter', 'asking', 'to', 'be', 'kept', 'fully', 'informed', 'on', 'Iraq', 'wheat', 'sales', '.'], ['Letters', 'from', 'John', 'Howard', 'and', 'Deputy', 'Prime', 'Minister', 'Mark', 'Vaile', 'to', 'AWB', 'have', 'been', 'released', 'by', 'the', 'Cole', 'inquiry', 'into', 'the', 'oil', 'for', 'food', 'program', '.'], ['In', 'one', 'of', 'the', 'letters', 'Mr', 'Howard', 'asks', 'AWB', 'managing', 'director', 'Andrew', 'Lindberg', 'to', 'remain', 'in', 'close', 'contact', 'with', 'the', 'Government', 'on', 'Iraq', 'wheat', 'sales', '.']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z-FE8Hoe4sIC",
        "outputId": "a8091155-e1f6-4482-88b7-48f8a92ca36d"
      },
      "source": [
        "# corpus 크기확인\n",
        "\n",
        "print(\"코퍼스의 크기 :\", len(corpus))\n",
        "#  약 29000여개의 샘플이 있음"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "코퍼스의 크기 : 29059\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-W4nzXTk43Rs"
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2pxm6XY49-H"
      },
      "source": [
        "model = Word2Vec(sentences = corpus, size = 100, window = 5, min_count = 5, workers = 4, sg = 0)\n",
        "\n",
        "# size : 학습후 차원\n",
        "# min_count : 최소 빈도수. 이보다 작으면 학습 X\n",
        "# 0 : cbow, 1: skip gram"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUIdM7Ij5JmI",
        "outputId": "1f6ea11b-be7c-48e9-a7d7-b7348f2d0bf1"
      },
      "source": [
        "# 유사도 테스트\n",
        "\n",
        "model_result = model.wv.most_similar(\"man\")\n",
        "\n",
        "print(model_result)\n",
        "\n",
        "# man과 가장 유사한 것이 woman인 것으로 나옴"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('woman', 0.9355605840682983), ('Bang', 0.9280612468719482), ('asteroid', 0.9213691353797913), ('third', 0.9179359674453735), ('skull', 0.9143943786621094), ('rally', 0.9109689593315125), ('infant', 0.9074746966362), ('baby', 0.9044082164764404), ('dog', 0.9040831923484802), ('conviction', 0.9033709764480591)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT2fpm6y5tiJ"
      },
      "source": [
        "from gensim.models import KeyedVectors"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gjt-d7MI59ps",
        "outputId": "3c6727e7-2507-4875-b27d-2fbf37dedced"
      },
      "source": [
        "# 모델 로드\n",
        "\n",
        "model.wv.save_word2vec_format(\"./w2v\")\n",
        "loaded_model = KeyedVectors.load_word2vec_format(\"./w2v\")\n",
        "\n",
        "print(\"모델 load 완료\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "모델 load 완료\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRXv9HoF6JlH",
        "outputId": "c83e79be-02b7-4b82-8151-1fdf6cfd0c16"
      },
      "source": [
        "# 로드한 모델이 이전과 같은 성능을 내는지 테스트\n",
        "\n",
        "model_result = loaded_model.wv.most_similar(\"man\")\n",
        "model_result\n",
        "\n",
        "# word 2 vec은 Oov 문제를 그대로 가지고 있음"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('woman', 0.9355605840682983),\n",
              " ('Bang', 0.9280612468719482),\n",
              " ('asteroid', 0.9213691353797913),\n",
              " ('third', 0.9179359674453735),\n",
              " ('skull', 0.9143943786621094),\n",
              " ('rally', 0.9109689593315125),\n",
              " ('infant', 0.9074746966362),\n",
              " ('baby', 0.9044082164764404),\n",
              " ('dog', 0.9040831923484802),\n",
              " ('conviction', 0.9033709764480591)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "fC9GQxmy6X78",
        "outputId": "fc661ce3-43d1-4147-a08c-b2e4f3d4d546"
      },
      "source": [
        "# overacting과 코사인 유사도가 가장 높은 단어 출력\n",
        "\n",
        "loaded_model.most_similar(\"overacting\")\n",
        "\n",
        "# 단어장에 존재하지 않는 단어이므로\n",
        "# 에러가 발생됨"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b1036531a078>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# overacting과 코사인 유사도가 가장 높은 단어 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"overacting\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'overacting' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "wvSdWe0W6q1J",
        "outputId": "0bcfb5c9-e70c-4e20-f04e-da980df5cc93"
      },
      "source": [
        "# 코사인 유사도 높은 단어 출력 2\n",
        "\n",
        "# 단어장에 존재하는 단어의 경우\n",
        "print(loaded_model.most_similar(\"memory\"))\n",
        "# 제대로 출력됨\n",
        "\n",
        "# 단어장에 존재하지 않는 단어의 경우\n",
        "print(loaded_model.most_similar('memorry'))\n",
        "# 오류가 발생함"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('jolt', 0.9722740650177002), ('structures', 0.9699009656906128), ('video', 0.9693214893341064), ('chasing', 0.9692908525466919), ('springs', 0.9688944816589355), ('lifting', 0.9688490629196167), ('infection', 0.9673976898193359), ('semen', 0.9667586088180542), ('display', 0.966754674911499), ('charged', 0.9655981063842773)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-82195da29e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 단어장에 존재하지 않는 단어의 경우\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'memorry'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'memorry' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skT6y0v47STZ",
        "outputId": "45fb5c54-86dd-49c7-e6db-3962b2432e9c"
      },
      "source": [
        "# install\n",
        "\n",
        "!pip install konlpy"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.3.0)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0tthly37d_u"
      },
      "source": [
        "# import \n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w46_0LUo7qC4",
        "outputId": "2af7a890-d30b-4600-fb50-3a75ebc51f34"
      },
      "source": [
        "# 네이버 영화 리뷰 데이터(감정분석과 관련된 데이터) 다운\n",
        "\n",
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\", filename=\"ratings.txt\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings.txt', <http.client.HTTPMessage at 0x7fa457b9de50>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ZQ1kSTVX7tio",
        "outputId": "7ccf360a-69f0-4adf-f4f7-d54788ff7e6f"
      },
      "source": [
        "# 리뷰 데이터 로드\n",
        "\n",
        "train_data = pd.read_table(\"ratings.txt\")\n",
        "train_data[:5]\n",
        "\n",
        "# human labeling 한 데이터가 들어있음\n",
        "# 긍정적인 데이터 1, 부정적인 데이터 0"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8112052</td>\n",
              "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8132799</td>\n",
              "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4655635</td>\n",
              "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9251303</td>\n",
              "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10067386</td>\n",
              "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
              "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
              "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
              "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
              "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CI_P465P7-3_",
        "outputId": "35698168-e3aa-46e3-b687-bcaaf0b157f4"
      },
      "source": [
        "# 리뷰 개수 확인\n",
        "\n",
        "len(train_data)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSyI3YuC8bUN",
        "outputId": "8eacc1b4-30d6-4b8f-ca2f-b350773f23dd"
      },
      "source": [
        "# null 값 확인\n",
        "\n",
        "print(train_data.isnull().values.any())\n",
        "# 어딘가에 널값이 있는지\n",
        "print()\n",
        "\n",
        "train_data.isnull().sum()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          0\n",
              "document    8\n",
              "label       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuFVfJUh8kE_",
        "outputId": "fc6c2905-0f75-4426-a7ca-34f647a5a91f"
      },
      "source": [
        "# null 값 제거\n",
        "\n",
        "train_data = train_data.dropna(how = \"any\")\n",
        "print(train_data.isnull().values.any())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jvxhR6ER86Hi",
        "outputId": "40d705ed-6b74-44dd-edd1-689418d000ca"
      },
      "source": [
        "# 한글외에 데이터를 제거하는 정규표현식\n",
        "\n",
        "train_data[\"document\"] = train_data[\"document\"].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\", \"\")\n",
        "train_data.head()\n",
        "# . 제거됨"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8112052</td>\n",
              "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8132799</td>\n",
              "      <td>디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4655635</td>\n",
              "      <td>폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9251303</td>\n",
              "      <td>와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10067386</td>\n",
              "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id                                           document  label\n",
              "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
              "1   8132799  디자인을 배우는 학생으로 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산업...      1\n",
              "2   4655635                   폴리스스토리 시리즈는 부터 뉴까지 버릴께 하나도 없음 최고      1\n",
              "3   9251303   와 연기가 진짜 개쩔구나 지루할거라고 생각했는데 몰입해서 봤다 그래 이런게 진짜 영화지      1\n",
              "4  10067386                         안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3QbrOVS9UrA"
      },
      "source": [
        "# 불용어 정의\n",
        "\n",
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3WF-HVF_7mR"
      },
      "source": [
        "okt = Okt()\n",
        "tokenized_data = []\n",
        "for sentence in train_data['document']:\n",
        "  temp_x = okt.morphs(sentence, stem=True) # 토큰화\n",
        "  temp_x = [word for word in temp_x if not word in stopwords] # 불용어 제거\n",
        "  tokenized_data.append(temp_x)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "nscdibLJAG2p",
        "outputId": "3af0c780-8dad-4b18-a521-4a5ab61f78b7"
      },
      "source": [
        "# 리뷰 길이 분포 확인\n",
        "print('리뷰의 최대 길이 :', max(len(l) for l in tokenized_data))\n",
        "print('리뷰의 평균 길이 :', sum(map(len, tokenized_data))/len(tokenized_data))\n",
        "plt.hist([len(s) for s in tokenized_data], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 72\n",
            "리뷰의 평균 길이 : 10.716703668146726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YoiMgDmCnVN"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(sentences = tokenized_data, size = 100, window=5, min_count=5, workers =4, sg=0)"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtcrQDpSCon-",
        "outputId": "b469226d-4933-465c-9304-9a3d4d87b596"
      },
      "source": [
        "# 사이즈\n",
        "\n",
        "model.wv.vectors.shape"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16477, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EKJGQSAII70",
        "outputId": "a926174f-f3ce-4e3b-e5c1-db3838a9adb0"
      },
      "source": [
        "print(model.wv.most_similar(\"최민식\"))\n",
        "print(model.wv.most_similar(\"히어로\"))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('한석규', 0.8720081448554993), ('안성기', 0.8522822260856628), ('송강호', 0.848280668258667), ('김명민', 0.8455771803855896), ('이정재', 0.8442631959915161), ('엄정화', 0.8346402645111084), ('엄태웅', 0.832843542098999), ('이민호', 0.8297013640403748), ('유해진', 0.8292660713195801), ('설경구', 0.8271686434745789)]\n",
            "[('호러', 0.9044381380081177), ('슬래셔', 0.8983699083328247), ('무협', 0.8781575560569763), ('무비', 0.8532706499099731), ('느와르', 0.8523597717285156), ('블록버스터', 0.8365192413330078), ('정통', 0.8291299939155579), ('판타지', 0.8155695199966431), ('블랙', 0.8098891377449036), ('물의', 0.8078872561454773)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWn1IQIMIRp3"
      },
      "source": [
        "## 사전 훈련된 워드 임베딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODm4y6HNKVD0"
      },
      "source": [
        "import gensim"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0EMWm2mKW2I"
      },
      "source": [
        "model = gensim.models.Word2Vec.load(\"/content/drive/MyDrive/dataset/ko.bin\")\n",
        "\n",
        "\n",
        "nodeldkjf"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esqSRl4FIY7P"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyXzvtkiKOHN"
      },
      "source": [
        "sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n",
        "y_train = [1, 0, 0, 1, 1, 0, 1]\n",
        "# 긍정, 부정"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpO704jfKgw7",
        "outputId": "cc3bb79b-3127-411b-b9be-709c11cfc2af"
      },
      "source": [
        "# 토큰화\n",
        "\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(sentences)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "\n",
        "print(vocab_size)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VPWkQtaCKq2P",
        "outputId": "54f0ba4d-47f6-4b13-bab4-a6dfe17a232c"
      },
      "source": [
        "# 인코딩\n",
        "# sentences 정수화\n",
        "\n",
        "x_encoded = t.texts_to_sequences(sentences)\n",
        "print(x_encoded)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahz8H-7TK1mP",
        "outputId": "d4561222-b372-4bb1-c298-a107d138c6a0"
      },
      "source": [
        "# 가장 길이가 긴것?\n",
        "\n",
        "max_len = max(len(l) for l in x_encoded)\n",
        "print(max_len)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIy-nLhiK7rQ",
        "outputId": "09659492-628a-42d4-9b44-f71ceebade2c"
      },
      "source": [
        "# Padding\n",
        "# 길이가 제각각 이므로\n",
        "# 제일 긴 단어를 기준으로 길이를 맞춰줄것\n",
        "# 길이 짧은 단어에는 0을 붙여 긴 단어랑 길이를 맞춰주는것\n",
        "\n",
        "x_train = pad_sequences(x_encoded, maxlen = max_len, padding = \"post\")\n",
        "# post이므로 뒤쪽에 패딩(0을 붙임)을 줌\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "print(x_train)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  2  3  4]\n",
            " [ 5  6  0  0]\n",
            " [ 7  8  0  0]\n",
            " [ 9 10  0  0]\n",
            " [11 12  0  0]\n",
            " [13  0  0  0]\n",
            " [14 15  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ijVXa-pLXS1"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpHadX42LrnP"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 4, input_length = max_len))\n",
        "# 차원을 무조건 4로 맞춰주겠다는것\n",
        "model.add(Flatten())\n",
        "# 모델 평평하게 해주기 위함\n",
        "model.add(Dense(1, activation = \"sigmoid\"))\n",
        "# dense로 학습 시킴, sigmoid로 output"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-P5b86KL4KQ",
        "outputId": "eaf29a72-f73d-444b-e332-15be9f715627"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 4, 4)              64        \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 81\n",
            "Trainable params: 81\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtNeE7MyMI3b",
        "outputId": "8490b241-5fa2-417f-df9e-0367dc962c72"
      },
      "source": [
        "# 학습\n",
        "\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = \"acc\")\n",
        "model.fit(x_train, y_train, epochs = 100, verbose = 2)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 - 3s - loss: 0.6851 - acc: 0.7143\n",
            "Epoch 2/100\n",
            "1/1 - 0s - loss: 0.6833 - acc: 0.7143\n",
            "Epoch 3/100\n",
            "1/1 - 0s - loss: 0.6814 - acc: 0.7143\n",
            "Epoch 4/100\n",
            "1/1 - 0s - loss: 0.6796 - acc: 0.7143\n",
            "Epoch 5/100\n",
            "1/1 - 0s - loss: 0.6777 - acc: 0.7143\n",
            "Epoch 6/100\n",
            "1/1 - 0s - loss: 0.6759 - acc: 0.7143\n",
            "Epoch 7/100\n",
            "1/1 - 0s - loss: 0.6740 - acc: 0.7143\n",
            "Epoch 8/100\n",
            "1/1 - 0s - loss: 0.6721 - acc: 0.7143\n",
            "Epoch 9/100\n",
            "1/1 - 0s - loss: 0.6703 - acc: 0.7143\n",
            "Epoch 10/100\n",
            "1/1 - 0s - loss: 0.6684 - acc: 0.7143\n",
            "Epoch 11/100\n",
            "1/1 - 0s - loss: 0.6666 - acc: 0.7143\n",
            "Epoch 12/100\n",
            "1/1 - 0s - loss: 0.6647 - acc: 0.8571\n",
            "Epoch 13/100\n",
            "1/1 - 0s - loss: 0.6629 - acc: 0.8571\n",
            "Epoch 14/100\n",
            "1/1 - 0s - loss: 0.6610 - acc: 0.8571\n",
            "Epoch 15/100\n",
            "1/1 - 0s - loss: 0.6592 - acc: 0.8571\n",
            "Epoch 16/100\n",
            "1/1 - 0s - loss: 0.6573 - acc: 0.8571\n",
            "Epoch 17/100\n",
            "1/1 - 0s - loss: 0.6554 - acc: 0.8571\n",
            "Epoch 18/100\n",
            "1/1 - 0s - loss: 0.6535 - acc: 0.8571\n",
            "Epoch 19/100\n",
            "1/1 - 0s - loss: 0.6517 - acc: 0.8571\n",
            "Epoch 20/100\n",
            "1/1 - 0s - loss: 0.6498 - acc: 0.8571\n",
            "Epoch 21/100\n",
            "1/1 - 0s - loss: 0.6479 - acc: 0.8571\n",
            "Epoch 22/100\n",
            "1/1 - 0s - loss: 0.6460 - acc: 0.8571\n",
            "Epoch 23/100\n",
            "1/1 - 0s - loss: 0.6441 - acc: 0.8571\n",
            "Epoch 24/100\n",
            "1/1 - 0s - loss: 0.6422 - acc: 0.8571\n",
            "Epoch 25/100\n",
            "1/1 - 0s - loss: 0.6403 - acc: 0.8571\n",
            "Epoch 26/100\n",
            "1/1 - 0s - loss: 0.6384 - acc: 0.8571\n",
            "Epoch 27/100\n",
            "1/1 - 0s - loss: 0.6364 - acc: 0.8571\n",
            "Epoch 28/100\n",
            "1/1 - 0s - loss: 0.6345 - acc: 0.8571\n",
            "Epoch 29/100\n",
            "1/1 - 0s - loss: 0.6326 - acc: 0.8571\n",
            "Epoch 30/100\n",
            "1/1 - 0s - loss: 0.6306 - acc: 0.8571\n",
            "Epoch 31/100\n",
            "1/1 - 0s - loss: 0.6287 - acc: 1.0000\n",
            "Epoch 32/100\n",
            "1/1 - 0s - loss: 0.6267 - acc: 1.0000\n",
            "Epoch 33/100\n",
            "1/1 - 0s - loss: 0.6247 - acc: 1.0000\n",
            "Epoch 34/100\n",
            "1/1 - 0s - loss: 0.6228 - acc: 1.0000\n",
            "Epoch 35/100\n",
            "1/1 - 0s - loss: 0.6208 - acc: 1.0000\n",
            "Epoch 36/100\n",
            "1/1 - 0s - loss: 0.6188 - acc: 1.0000\n",
            "Epoch 37/100\n",
            "1/1 - 0s - loss: 0.6168 - acc: 1.0000\n",
            "Epoch 38/100\n",
            "1/1 - 0s - loss: 0.6148 - acc: 1.0000\n",
            "Epoch 39/100\n",
            "1/1 - 0s - loss: 0.6128 - acc: 1.0000\n",
            "Epoch 40/100\n",
            "1/1 - 0s - loss: 0.6108 - acc: 1.0000\n",
            "Epoch 41/100\n",
            "1/1 - 0s - loss: 0.6087 - acc: 1.0000\n",
            "Epoch 42/100\n",
            "1/1 - 0s - loss: 0.6067 - acc: 1.0000\n",
            "Epoch 43/100\n",
            "1/1 - 0s - loss: 0.6047 - acc: 1.0000\n",
            "Epoch 44/100\n",
            "1/1 - 0s - loss: 0.6026 - acc: 1.0000\n",
            "Epoch 45/100\n",
            "1/1 - 0s - loss: 0.6006 - acc: 1.0000\n",
            "Epoch 46/100\n",
            "1/1 - 0s - loss: 0.5985 - acc: 1.0000\n",
            "Epoch 47/100\n",
            "1/1 - 0s - loss: 0.5965 - acc: 1.0000\n",
            "Epoch 48/100\n",
            "1/1 - 0s - loss: 0.5944 - acc: 1.0000\n",
            "Epoch 49/100\n",
            "1/1 - 0s - loss: 0.5923 - acc: 1.0000\n",
            "Epoch 50/100\n",
            "1/1 - 0s - loss: 0.5902 - acc: 1.0000\n",
            "Epoch 51/100\n",
            "1/1 - 0s - loss: 0.5881 - acc: 1.0000\n",
            "Epoch 52/100\n",
            "1/1 - 0s - loss: 0.5860 - acc: 1.0000\n",
            "Epoch 53/100\n",
            "1/1 - 0s - loss: 0.5839 - acc: 1.0000\n",
            "Epoch 54/100\n",
            "1/1 - 0s - loss: 0.5818 - acc: 1.0000\n",
            "Epoch 55/100\n",
            "1/1 - 0s - loss: 0.5797 - acc: 1.0000\n",
            "Epoch 56/100\n",
            "1/1 - 0s - loss: 0.5776 - acc: 1.0000\n",
            "Epoch 57/100\n",
            "1/1 - 0s - loss: 0.5755 - acc: 1.0000\n",
            "Epoch 58/100\n",
            "1/1 - 0s - loss: 0.5733 - acc: 1.0000\n",
            "Epoch 59/100\n",
            "1/1 - 0s - loss: 0.5712 - acc: 1.0000\n",
            "Epoch 60/100\n",
            "1/1 - 0s - loss: 0.5691 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "1/1 - 0s - loss: 0.5669 - acc: 1.0000\n",
            "Epoch 62/100\n",
            "1/1 - 0s - loss: 0.5648 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "1/1 - 0s - loss: 0.5626 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "1/1 - 0s - loss: 0.5605 - acc: 1.0000\n",
            "Epoch 65/100\n",
            "1/1 - 0s - loss: 0.5583 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "1/1 - 0s - loss: 0.5561 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "1/1 - 0s - loss: 0.5539 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "1/1 - 0s - loss: 0.5518 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "1/1 - 0s - loss: 0.5496 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "1/1 - 0s - loss: 0.5474 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "1/1 - 0s - loss: 0.5452 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "1/1 - 0s - loss: 0.5430 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "1/1 - 0s - loss: 0.5408 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "1/1 - 0s - loss: 0.5386 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "1/1 - 0s - loss: 0.5364 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "1/1 - 0s - loss: 0.5342 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "1/1 - 0s - loss: 0.5320 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "1/1 - 0s - loss: 0.5298 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "1/1 - 0s - loss: 0.5276 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "1/1 - 0s - loss: 0.5253 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "1/1 - 0s - loss: 0.5231 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "1/1 - 0s - loss: 0.5209 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "1/1 - 0s - loss: 0.5187 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "1/1 - 0s - loss: 0.5165 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "1/1 - 0s - loss: 0.5142 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "1/1 - 0s - loss: 0.5120 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "1/1 - 0s - loss: 0.5098 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "1/1 - 0s - loss: 0.5075 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "1/1 - 0s - loss: 0.5053 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "1/1 - 0s - loss: 0.5031 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "1/1 - 0s - loss: 0.5008 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "1/1 - 0s - loss: 0.4986 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "1/1 - 0s - loss: 0.4963 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "1/1 - 0s - loss: 0.4941 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "1/1 - 0s - loss: 0.4919 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "1/1 - 0s - loss: 0.4896 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "1/1 - 0s - loss: 0.4874 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "1/1 - 0s - loss: 0.4851 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "1/1 - 0s - loss: 0.4829 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "1/1 - 0s - loss: 0.4807 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa3dfdb50d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVW4vNssMfy4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}